\newcommand{\zero}{\ensuremath{\mathbf{0}}\xspace}
\newcommand{\one}{\ensuremath{\mathbf{1}}\xspace}
\newcommand{\two}{\ensuremath{\mathbf{2}}\xspace}
\newcommand{\three}{\ensuremath{\mathbf{3}}\xspace}
\newcommand{\nat}{\ensuremath{\mathbf{N}}\xspace}
\newcommand{\true}{\ensuremath{\mathbf{true}}\xspace}
\newcommand{\false}{\ensuremath{\mathbf{false}}\xspace}
\newcommand{\rec}{\ensuremath{\mathbf{rec}}\xspace}
\newcommand{\z}{\ensuremath{0}\xspace}
\newcommand{\s}{\ensuremath{\mathbf{s}}\xspace}
\newcommand{\alt}{\;|\;\;}
\newcommand{\der}{\vdash}

\chapter{Induction}
\label{cha:induction}

% Local Variables:
% TeX-master: "main"
% End:

An \emph{inductive type} can be intuitively understood as a type generated by a certain finite collection of constructors. To specify an inductive type formally,
we will use a schematic definition, where we list the name and type of each constructor separately, e.g.:
\begin{align*}
  \two \defeq \; & \true : \two \\
         \alt & \false : \two
\end{align*}
The above definition declares the type $\two$ of Booleans to be the inductive type generated by two constant constructors $\true$ and $\false$. We can similarly define the types $\zero$ (aka Empty, Void), $\one$ (aka Unit), $\three$, and so on, with 0, 1, 3, or more constructors respectively. 

Another extremely important inductive type is the type $\nat$ of natural numbers:  
\begin{align*}
  \nat \defeq \; & \z : \nat \\
        \alt & \s : \nat \to \nat 
\end{align*}
As expected, $\nat$ is generated by a constant constructor $\z$ for the natural number zero and a unary constructor $\s$ taking a natural number $n : \nat$ to its successor $\s(n) : \nat$. It is understood that for any inductive type, different constructors construct different terms and each constructor itself is injective. This ensures that as desired, 0 is not a successor of any other natural number and that no two natural numbers have the same successor.

What can we do with such an inductive type? An intuitive understanding of an inductive type $A$ is that it \emph{behaves as if the only inhabitants of $A$ were the terms constructed solely by applying the constructors of $A$}; we refer to these particular terms as the \emph{canonical terms of $A$}. In an empty context,
each term of $A$ is canonical - for instance, any closed term of an identity type is necessarily the identity path. In the setting of nonempty contexts,  
interesting and often nontrivial behavior may occur, such as the one exhibited by identity types which behave much like paths in a space.

In the case of the type $\two$ of Booleans, assuming that each term is canonical simply means that each term $b : \two$ must be either $\true$ or $\false$. In particular, we have the principle of \emph{(dependent) elimination}:

\begin{itemize}
\item When proving a statement $\Gamma \der E : \prd{b : \two} \type$ about \emph{all} Booleans, it suffices to prove it for $\true$ and $\false$, i.e., give proofs
$\Gamma \der e_t : E(\true)$ and $\Gamma \der e_f : E(\false)$.
\end{itemize}

Furthermore, the resulting proof $\Gamma \der \rec_\two(E,e_t,e_f): \prd{b : \two}E(b)$ behaves as expected when applied to the constructors $\true$ and $\false$; this principle is expressed by the \emph{computation rules}:
\begin{itemize}
\item The proof $\Gamma \der \rec_\two(E,e_t,e_f,\true) : E(\true)$ is identical to $e_t$.
\item The proof $\Gamma \der \rec_\two(E,e_t,e_f,\false) : E(\true)$ is identical to $e_f$.
\end{itemize}
For simplicity we often omit the ambient context $\Gamma$.

The rules for the type $\two$ of Booleans allow us to reason by \emph{case analysis}. Since neither of the two constructors takes any arguments, this is all we need for Booleans. However, for more complex types such as the type $\nat$ of natural numbers, true induction is often needed (hence the name \emph{inductive type}):

\begin{itemize}
\item When proving a statement $E : \prd{x : \nat} \type$ about \emph{all} natural numbers, it suffices to prove it for $\z$ and for $\s(n)$, assuming it holds
for $n$. This entails giving the proofs $e_z : E(\z)$ and $e_s : \prd{n : \nat}{y : E(n)} E(\s(n))$.
\end{itemize}
The variable $y$ represents our inductive hypothesis. As for Booleans, we also have the associated computation rules for the function $\rec_\nat(E,e_z,e_s) : \prd{x:\nat} E(x)$:
\begin{itemize}
\item The proof $\rec_\nat(E,e_z,e_s,\z) : E(\z)$ is identical to $e_z$.
\item For any $n : \nat$, the proof $\rec_\nat(E,e_z,e_s,\s(n)) : E(\s(n))$ is identical to $e_s(n,\rec_\nat(E,e_z,e_s,n))$.
\end{itemize}
The dependent function $\rec_\nat(E,e_z,e_s)$ can thus be understood as being defined recursively on the argument $x : \nat$, via the recurrence determined by $e_z$ and $e_s$: When $x$ is zero, the function simply returns $e_z$. When $x$ is the successor of another natural number $n$, the result is obtained by taking the recurrence $e_s$ and plugging in the specific predecessor $n$ and the recursive call value $\rec_\nat(E,e_z,e_s,n)$.

This induction principle is rather strong and allows us to prove a variety of interesting theorems. For example, by specifying the terms $e_z$ and $e_s$, we  uniquely determine how the recursor behaves on canonical terms, and thus on all natural numbers. If we now have another function which obeys the same recurrence, then our intuition suggests these two functions should be pointwise equal. It turns out this is indeed the case and we have the following \emph{uniqueness principle}:

\begin{thm}
Let $f,g : \prd{x:\nat} E(x)$ be two functions which satisfy the recurrences $e_z$ and $e_s$ up to propositional equality, i.e., such that
\begin{align*}
\id{f(\z)}{e_z} \\ 
\id{g(\z)}{e_z}
\end{align*}
and 
\begin{align*}
\prd{n : \nat} \id{f(\s(n))}{e_s(n, f(n))} \\
\prd{n : \nat} \id{g(\s(n))}{e_s(n, g(n))}
\end{align*}
Then $f$ and $g$ are pointwise equal, i.e., we have a term $\alpha : \prd{x : \nat} \idtype{f(x)}{g(x)}$.
\end{thm}

\begin{proof}
We use dependent elimination with the type $E(x) \defeq \id{f(x)}{g(x)}$. For the base case, we have \[f(\z) = e_z = g(\z)\]
For the inductive case, assume we have $n : \nat$ such that $f(n) = g(n)$. Then
\[ f(\s(n)) = e_s(n, f(n)) = e_s(n, g(n)) = g(\s(n)) \]
The first and last equality follow from the assumptions on $f$ and $g$. The middle equality follows from the inductive hypothesis and the fact that application preserves equality.
\end{proof}
Analogous uniqueness theorem can generally be shown for any other inductive type.

