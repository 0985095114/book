\chapter{Homotopy type theory}
\label{cha:basics}

\section{Types are higher groupoids}
\label{sec:equality}

Recall that for any type $A$, and any $x,y:A$, we have a identity type $\id[A]{x}{y}$, also written $\idtype[A]{x}{y}$ or just $x=y$.
We can think of inhabitants of $x=y$ as either
\begin{enumerate}
\item proofs or evidence that $x$ and $y$ are equal,
\item identifications of $x$ with $y$,
\item paths from $x$ to $y$, or
\item isomorphisms/equivalences from $x$ to $y$.
\end{enumerate}
The first is more traditional in type theory; but in homotopy type theory we often take the latter perspectives as well.
It turns out that the defining rules of identity types, as described in the previous chapter, give them structure which corresponds precisely to that of a space or a higher groupoid.

Recall that the induction principle for the identity types $\id[A]{x}{y}$ (with $A$ a fixed type) says that if
\begin{itemize}
\item for every $x,y:A$ and every $p:\id[A]xy$ we have a type $D(x,y,p)$, and
\item for every $a:A$ we have an element $d(a):D(a,a,\refl a)$, 
\end{itemize}
then
\begin{itemize}
\item there exists an element $J_{D,d}(x,y,p):D(x,y,p)$ for \emph{every} two elements $x,y:A$ and $p:\id[A]xy$, such that $J_{D,d}(a,a,\refl a) \jdeq d(a)$.
\end{itemize}
In other words, given dependent functions
\begin{align*}
D & :\prd{x,y:A}{p:\id{x}{y}} \type\\
d & :\prd{a:A} D(a,a,\refl{a})
\end{align*}
there is a dependent function
\[J_{D,d}:\prd{x,y:A}{p:\id{x}{y}} D(x,y,p)\]
such that 
\begin{equation}\label{eq:Jconv}
J_{D,d}(a,a,\refl{a})\jdeq d(a)
\end{equation}
for every $a:A$.
The notation $J$ is traditional for this function, but we will not use it very much.
Usually, every time we apply this induction rule we will either not care about the specific function being defined, or we will immediately give it a different name.

Informally, the induction principle for identity types says that if we want to construct an object (or prove a statement) which depends on an inhabitant $p:\id[A]xy$ of an identity type, then it suffices to perform the construction (or the proof) in the special case when $x$ and $y$ are the same (judgmentally) and $p$ is a reflexivity term $\refl{x}$ (judgmentally).
When writing informally, we may express this with a phrase such as ``by induction, it suffices to assume\dots''.
This reduction to the ``reflexivity case'' is analogous to the reduction to the ``base case'' and ``inductive step'' in an ordinary proof by induction on the natural numbers, and also to the ``left case'' and ``right case'' in a proof by case analysis on a disjoint union or disjunction.

The ``conversion rule''~\eqref{eq:Jconv} is less familiar in the context of proof by induction on natural numbers, but there is an analogous notion in the related concept of definition by recursion.
If a sequence $(a_n)_{n\in \mathbb{N}}$ is defined by giving $a_0$ and specifying $a_{n+1}$ in terms of $a_n$, then in fact the $0^{\mathrm{th}}$ term of the resulting sequence \emph{is} the given one, and the given recurrence relation relating $a_{n+1}$ to $a_n$ holds for the resulting sequence.
(This may seem so obvious as to not be worth saying, but if we view a definition by recursion as an algorithm for calculating values of a sequence, then it is precisely the process of executing that algorithm.)
The rule~\eqref{eq:Jconv} is analogous: it says that if we define an object $f(p)$ for all $p:x=y$ by specifying what the value should be when $p$ is $\refl{x}:x=x$, then the value we specified is in fact the value of $f(\refl{x})$.

We now derive from this induction principle all the structure of a higher groupoid.
We begin with symmetry of equality, which, in topological language, means that ``paths can be reversed''.

\begin{lem}\label{lem:opp}
  For every type $A$ and every $x,y:A$ there is a function
  \begin{equation*}
    (x= y)\to(y= x)
  \end{equation*}
  denoted $p\mapsto \opp{p}$, such that $\opp{\refl{x}}\jdeq\refl{x}$ for each $x:A$.
\end{lem}
\begin{proof}[First proof]
  Let $D:\prd{x,y:A}{p:x= y} \type$ be the dependent type defined by $D(x,y,p)\defeq (y= x)$.
  In other words, $D$ is a function assigning to any $x,y:A$ and $p:x=y$ a type, namely the type $y=x$.
  Then we have
  \begin{equation*}
    d\defeq \lambda x.\refl{x}:\prd{x:A} D(x,x,\refl{x}).
  \end{equation*}
  Thus, the eliminator $J$ for identity types gives us a term $J_{D,d}(x,y,p): (y= x)$ for each $p:(x= y)$.
  We can now define the desired function $\opp{(-)}$ to be $\lambda p. J_{D,d}(x,y,p)$, i.e.\ we set $\opp{p} \defeq J_{D,d}(x,y,p)$.
  The conversion rule~\eqref{eq:Jconv} gives $\opp{\refl{x}}\jdeq \refl{x}$.
\end{proof}

We have written out this proof in a very formal style, which may be helpful while the induction rule on identity types is unfamiliar.
However, eventually we prefer to use more natural language, such as in the following equivalent proof.

\begin{proof}[Second proof]
  We want to construct, for each $x,y:A$ and $p:x=y$, an element $\opp{p}:y=x$.
  By induction, it suffices to do this in the case when $y$ is $x$ and $p$ is $\refl{x}$.
  But in this case, the type $x=y$ of $p$ and the type $y=x$ in which we are trying to construct $\opp{p}$ are both simply $x=x$.
  Thus, in the ``reflexivity case'', we can define $\opp{\refl{x}}$ to be simply $\refl{x}$.
  The general case then follows by the induction principle, and the conversion rule $\opp{\refl{x}}\jdeq\refl{x}$ is precisely the proof in the reflexivity case that we gave.
\end{proof}

We will write out the next few proofs in both styles, to help the reader become accustomed to the latter one.
Next we prove the transitivity of equality, or equivalently we ``concatenate paths''.

\begin{lem}\label{lem:concat}
  For every type $A$ and every $x,y,z:A$ there is a function
  \begin{equation*}
    (x= y) \to (y= z)\to (x=  z)
  \end{equation*}
  written $(p,q)\mapsto p\ct q$, such that $\refl{x}\ct \refl{x}\jdeq \refl{x}$ for any $x:A$.
\end{lem}

\begin{proof}[First proof]
  Let $D:\prd{x,y:A}{p:x=y} \type$ be the dependent type
  \begin{equation*}
    D(x,y,p)\defeq \prd{z:A}{q:y=z} (x=z).
  \end{equation*}
  Note that $D(x,x,\refl x) \jdeq \prd{z:A}{q:x=z} (x=z)$.
  Thus, in order to apply the induction principle for identity types to this $D$, we need a function of type
  \begin{equation}\label{eq:concatD}
    \prd{x:A} D(x,x,\refl{x})
    \jdeq \prd{x,z:A}{q:x=z} (x=z).
  \end{equation}
  Now let $E:\prd{x,z:A}{q:x=z}\type$ be the dependent type $E(x,z,q)\defeq (x=z)$.
  Note that $E(x,x,\refl x) \jdeq (x=x)$.
  Thus, we have the function
  \begin{equation*}
    e(x) \defeq \refl{x} : E(x,x,\refl{x}).
  \end{equation*}
  By the induction principle for identity types applied to $E$, we obtain a function
  \begin{equation*}
    d(x,z,q) : \prd{x,z:A}{q:x=z} E(x,z,q) \jdeq \prd{x,z:A}{q:x=z} (x=z)
  \end{equation*}
  which is~\eqref{eq:concatD}.
  Thus, we can use this function $d$ and apply the induction principle for identity types to $D$, to obtain our desired function of type
  \begin{equation*}
    \prd{x,y,z:A}{q:y=z}{p:x=y} (x=z).
  \end{equation*}
  The conversion rules for the two induction principles give us $\refl{x}\ct \refl{x}\jdeq \refl{x}$ for any $x:A$.
\end{proof}

\begin{proof}[Second proof]
  We want to construct, for every $x,y,z:A$ and every $p:x=y$ and $q:y=z$, an element of $x=z$.
  By induction on $p$, it suffices to assume that $y$ is $x$ and $p$ is $\refl{x}$.
  In this case, the type $y=z$ of $q$ is $x=z$.
  Now by induction on $q$, it suffices to assume also that $z$ is $x$ and $q$ is $\refl{x}$.
  But in this case, $x=z$ is $x=x$, and we have $\refl{x}:(x=x)$.
\end{proof}

The reader may well feel that we have given an overly convoluted proof of this lemma.
In fact, we could stop after the induction on $p$, since at that point what we want to produce is an equality $x=z$, and we already have such an equality, namely $q$.
Why do we go on to do another induction on $q$?

The answer is that, as described in the introduction, we are doing \emph{proof-relevant} mathematics.
When we prove a lemma, we are defining an inhabitant of some type, and it can matter what \emph{specific} element we defined in the course of the proof, not merely the type that that element inhabits (that is, the \emph{statement} of the lemma).
\autoref{lem:concat} has three obvious proofs: we could do induction over $p$, induction over $q$, or induction over both of them.
If we proved it three different ways, we would have three different elements of the same type.
It's not hard to show that these three elements would be (provably) \emph{equal} (see \autoref{ex:basics:concat}), but there can still be reasons to prefer a particular definition over a provably equal one.

In the case of \autoref{lem:concat}, the difference hinges on the computation rule.
If we proved the lemma using a single induction over $p$, then we would end up with a computation rule of the form $\refl{y} \ct q \jdeq q$.
If we proved it with a single induction over $q$, we would have instead $p\ct\refl{x}\jdeq p$, while proving it with a double induction (as we did) gives only $\refl{x}\ct\refl{x} \jdeq \refl{x}$.

The asymmetrical computation rules can sometimes be convenient when doing formalized mathematics, as they allow the computer to simplify more things automatically.
However, in informal mathematics, and arguably even in the formalized case, it can be confusing to have a concatenation operation which behaves asymmetrically and to have to remember which side is the ``special'' one.
Treating both sides symmetrically makes for more robust proofs; this is why we have given the proof that we did.
(However, this is admittedly a stylistic choice.)

The table below summarizes the ``equality'' and ``homotopical'' points of view on what we have done so far.
\begin{center}
  \begin{tabular}{c|c}
    Equality & Homotopy \\\hline
    reflexivity & constant path\\
    symmetry & inversion of paths\\
    transitivity & concatenation of paths
  \end{tabular}
\end{center}

However, proof-relevance also means that we can't stop after proving ``symmetry'' and  ``transitivity'' of equality: we need to know that these \emph{operations} on equalities are well-behaved.
(This issue is invisible to set-level mathematics, where symmetry and transitivity are mere \emph{properties} of equality, rather than structure on paths.)
For instance, we need to know that concatenation is \emph{associative}, and that inversion provides \emph{inverses} with respect to concatenation.
This is to be expected from the topological point of view, where these are regarded as \emph{operations} on paths.

\begin{lem}\label{thm:omg}%[The $\omega$-groupoid structure of types]
  Suppose $A:\type$, that $x,y,z,w:A$ and that $p:x= y$ and $q:y = z$ and $r:z=w$.
  We have the following:
  \begin{enumerate}
  \item $p= p\ct \refl{y}$ and $p = \refl{x} \ct p$.\label{item:omg1}
  \item $\opp{p}\ct p=  \refl{y}$ and $p\ct \opp{p}= \refl{x}$.
  \item $\opp{(\opp{p})}= p$.
  \item $p\ct (q\ct r)=  (p\ct q)\ct r$.\label{item:omg4}
  \end{enumerate}
\end{lem}

Note, in particular, that~\ref{item:omg1}--\ref{item:omg4} are themselves propositional equalities, living in the identity types of the identity types $x=y$.
Topologically, they are \emph{paths of paths}, and we are familiar topologically with the idea that concatenating a path with the reversed path only gives a constant path \emph{up to homotopy}, i.e.\ up to a higher path.
The paths~\ref{item:omg1}--\ref{item:omg4} also satisfy their own higher coherence laws, which are themselves higher paths, and so on all the way up.

However, for most purposes it is unnecessary to make the whole infinite-dimensional structure explicit.
One of the nice things about homotopy type theory is that all of this structure can be \emph{proven} starting from only the inductive property of identity types, so we can make explicit as much or as little of it as we need.
In particular, often we don't need the complicated combinatorics involved in making precise notions such as ``coherent structure at all higher levels''.

\begin{proof}[Proof of~\autoref{thm:omg}]
  All the proofs use the induction principle for equalities.
  \begin{enumerate}
  \item \emph{(First proof)} Let $D:\prd{x,y:A}{p:x=y} \type$ be the dependent type given by 
    \begin{equation*}
      D(x,y,p)\defeq (p= p\ct \refl{y}).
    \end{equation*}
    Then $D(x,x,\refl{x})$ is $\refl{x}=\refl{x}\ct\refl{x}$.
    Since $\refl{x}\ct\refl{x}\jdeq\refl{x}$, it follows that $D(x,x,\refl{x})\jdeq (\refl{x}=\refl{x})$.
    Thus, there is a term
    \begin{equation*}
      d\defeq\lambda x.\refl{\refl{x}}:\prd{x:A} D(x,x,\refl{x}).
    \end{equation*}
    Now $J$ gives a term $J(D,d,p):(p= p\ct\refl{y})$ for each $p:x= y$.
    The other equality is proven similarly.

    \noindent
    \emph{(Second proof)} By induction on $p$, it suffices to assume that $y$ is $x$ and that $p$ is $\refl x$.
    But in this case, we have $\refl{x}\ct\refl{x}\jdeq\refl{x}$.
  \item \emph{(First proof)} Let $D:\prd{x,y:A}{p:x=y} \type$ be the dependent type given by 
    \begin{equation*}
      D(x,y,p)\defeq (\opp{p}\ct p=  \refl{y}).
    \end{equation*}
    Then $D(x,x,\refl{x})$ is $\opp{\refl{x}}\ct\refl{x}=\refl{x}$.
    Since $\opp{\refl{x}}\jdeq\refl{x}$ and $\refl{x}\ct\refl{x}\jdeq\refl{x}$, we get that $D(x,x,\refl{x})\jdeq (\refl{x}=\refl{x})$.
    Hence we find the function
    \begin{equation*}
      d\defeq\lambda x.\refl{\refl{x}}:\prd{x:A} D(x,x,\refl{x}).
    \end{equation*}
    Now $J$ gives a term $J(D,d,p):\opp{p}\ct p=\refl{y}$ for each $p:x= y$ in $A$.
    The other equality is similar.

    \noindent \emph{(Second proof)} By induction, it suffices to assume $p$ is $\refl x$.
    But in this case, we have $\opp{p} \ct p \jdeq \opp{\refl x} \ct \refl x \jdeq \refl x$.
  \item \emph{(First proof)} Let $D:\prd{x,y:A}{p:x=y} \type$ be the dependent type given by
    \begin{equation*}
      D(x,y,p)\defeq (\opp{\opp{p}}= p).
    \end{equation*}
    Then $D(x,x,\refl{x})$ is the type $(\opp{\opp{\refl x}}=\refl{x})$.
    But since $\opp{\refl{x}}\jdeq \refl{x}$ for each $x:A$, we have $\opp{\opp{\refl{x}}}\jdeq \opp{\refl{x}} \jdeq\refl{x}$, and thus $D(x,x,\refl{x})\jdeq(\refl{x}=\refl{x})$.
    Hence we find the function
    \begin{equation*}
      d\defeq\lambda x.\refl{\refl{x}}:\prd{x:A} D(x,x,\refl{x}).
    \end{equation*}
    Now $J$ gives a term $J(D,d,p):\opp{\opp{p}}= p$ for each $p:x= y$.

    \noindent \emph{(Second proof)} By induction, it suffices to assume $p$ is $\refl x$.
    But in this case, we have $\opp{\opp{p}}\jdeq \opp{\opp{\refl x}} \jdeq \refl x$.
  \item \emph{(First proof)} Let $D_1:\prd{x,y:A}{p:x=y} \type$ be the dependent type given by
    \begin{equation*}
      D_1(x,y,p)\defeq\prd{z,w:A}{q:y= z}{r:z= w} \big(p\ct (q\ct r)=  (p\ct q)\ct r\big).
    \end{equation*}
    Then $D_1(x,x,\refl{x})$ is
    \begin{equation*}
      \prd{z,w:A}{q:x= z}{r:z= w} \big(\refl{x}\ct(q\ct r)= (\refl{x}\ct q)\ct r\big).
    \end{equation*}
    To construct a term in this type, let $D_2:\prd{x,z:A}{q:x=z} \type$ be the dependent type
    \begin{equation*}
      D_2 (x,z,q) \defeq \prd{w:A}{r:z=w} \big(\refl{x}\ct(q\ct r)= (\refl{x}\ct q)\ct r\big).
    \end{equation*}
    Then $D_2(x,x,\refl{x})$ is
    \begin{equation*}
      \prd{w:A}{r:x=w} \big(\refl{x}\ct(\refl{x}\ct r)= (\refl{x}\ct \refl{x})\ct r\big).
    \end{equation*}
    To construct a term in \emph{this} type, let $D_3:\prd{x,w:A}{r:x=w} \type$ be the dependent type
    \begin{equation*}
      D_3(x,w,r) \defeq \big(\refl{x}\ct(\refl{x}\ct r)= (\refl{x}\ct \refl{x})\ct r\big).
    \end{equation*}
    Then $D_3(x,x,\refl{x})$ is
    \begin{equation*}
      \big(\refl{x}\ct(\refl{x}\ct \refl{x})= (\refl{x}\ct \refl{x})\ct \refl{x}\big)
    \end{equation*}
    which is definitionally equal to the type $(\refl{x} = \refl{x})$, and is therefore inhabited by $\refl{\refl{x}}$.
    Applying the identity elimination rule three times, therefore, we obtain a term of the overall desired type.

    \noindent \emph{(Second proof)} By induction, it suffices to assume $p$, $q$, and $r$ are all $\refl x$.
    But in this case, we have
    \begin{align*}
      p\ct (q\ct r)
      &\jdeq \refl{x}\ct(\refl{x}\ct \refl{x})\\
      &\jdeq \refl{x}\\
      &\jdeq (\refl{x}\ct \refl x)\ct \refl x\\
      &\jdeq (p\ct q)\ct r.
    \end{align*}
    Thus, we have $\refl{\refl{x}}$ inhabiting this type.\qedhere
  \end{enumerate}
\end{proof}

\begin{rmk}
  There are other ways to define all of these higher paths.
  For instance, in \autoref{thm:omg}\ref{item:omg4} we might do induction only over one or two paths rather than all three.
  All possibilities will produce \emph{definitionally} different proofs, but they will always be propositionally the same.
  Such an equality between any two particular proofs can, again, be proven by induction, reducing all the paths in question to reflexivities and then observing that both proofs reduce themselves to reflexivities.
\end{rmk}

\section{Functions are functors}
\label{sec:functors}

Now we wish to establish that functions $f:A\to B$ behave functorially on paths.
In traditional type theory, this is equivalently the statement that functions respect equality.
Topologically, this corresponds to saying that every function is ``continuous'', i.e.\ preserves paths.

\begin{lem}\label{lem:map}
  Suppose that $f:A\to B$ is a function and that $p:(\id[A]xy)$.
  Then for any $x,y:A$ there is an operation
  \begin{equation*}
    \apfunc f : (x=y) \to (f(x)= f(y)).
  \end{equation*}
  Moreover, for each $x:A$ we have $\apfunc{f}(\refl{x})\jdeq \refl{f(x)}$.
\end{lem}

The notation $\apfunc f$ can be read either as the \underline{ap}plication of $f$ to a path, or as the \underline{a}ction on \underline{p}aths of $f$.

\begin{proof}[First proof]
  Let $D:\prd{x,y:A}{p:x=y}\type$ be the dependent type defined by
  \[D(x,y,p)\defeq (f(x)= f(y)).\]
  Then we have
  \begin{equation*}
    d\defeq\lambda x.\refl{f(x)}:\prd{x:A} D(x,x,\refl{x}).
  \end{equation*}
  Applying $J$, we obtain $\apfunc f : \prd{x,y:A}{p:x=y}(f(x)=g(x))$.
  The conversion rule implies $\apfunc f({\refl{x}})\jdeq\refl{f(x)}$ for each $x:A$.
\end{proof}

\begin{proof}[Second proof]
  By induction, it suffices to assume $p$ is $\refl{x}$.
  In this case, we may define $\apfunc f(p) \defeq \refl{f(x)}:f(x)\jdeq f(x)$.
\end{proof}

We will often write $\apfunc f (p)$ as simply $\ap f p$.
This is strictly speaking ambiguous, but generally no confusion arises.
It matches the common convention in category theory of using the same symbol for the application of a functor to objects and to morphisms.

Now, since \emph{dependently typed} functions are very important in type theory, we will also need a version of \autoref{lem:map} for these.
However, this is not quite so simple to state, because if $f:\prd{x:A} B(x)$ and $p:x=y$, then $f(x):B(x)$ and $f(y):B(y)$ are elements of distinct types, so that \emph{a priori} we cannot even ask whether they are equal.
The missing ingredient is that $p$ itself gives us a way to relate the types $B(x)$ and $B(y)$.

\begin{lem}[Transport]\label{lem:transport}
  Suppose that $P$ is a dependent type over $A$ and that $p:\id[A]xy$.
  Then there is a function $\transf{p}:P(x)\to P(y)$.
\end{lem}

\begin{proof}[First proof]
  Let $D:\prd{x,y:A}{p:\id{x}{y}} \type$ be the dependent type defined by
  \[D(x,y,p)\defeq P(x)\to P(y).\]
  Then we have the function
  \begin{equation*}
    d\defeq\lambda x.\idfunc[P(x)]:\prd{x:A} D(x,x,\refl{x}),
  \end{equation*}
  so that the induction principle gives us $J_{D,d}(x,y,p):P(x)\to P(y)$ for $p:x= y$, which we define to be $\transf p$.
\end{proof}

\begin{proof}[Second proof]
  By induction, it suffices to assume $p$ is $\refl x$.
  But in this case, we can take $\transf{(\refl x)}:P(x)\to P(x)$ to be the identity function.
\end{proof}

Sometimes, it is necessary to notate the dependent type $P$ in which the transport operation happens.
In this case, we may write
\[\transfib P p - : P(x) \to P(y).\]

Recall that a dependent type $P$ over a type $A$ can be seen as a property of elements of $A$, which holds at $x$ in $A$ if $P(x)$ is inhabited.
Then the transportation lemma says that if $x$ is propositionally equal to $y$, then $P(x)$ holds if and only if $P(y)$ holds.
In fact, we will see later on that if $x=y$ then actually $P(x)$ and $P(y)$ are \emph{equivalent}.

Now we can prove the dependent version of \autoref{lem:map}.

\begin{lem}[Dependent map]\label{lem:mapdep}
  Suppose $f:\prd{x: A} P(x)$; then we have
  \[\apdfunc f :(x=y) \to \big(\id[P(y)]{\trans p{f(x)}}{f(y)}\big).\]
\end{lem}

\begin{proof}[First proof]
  Let $D:\prd{x,y:A}{p:\id{x}{y}} \type$ be the dependent type defined by
  \begin{equation*}
    D(x,y,p)\defeq \trans p {f(x)}= f(y).
  \end{equation*}
  Then $D(x,x,\refl{x})$ is $\trans{(\refl{x})}{f(x)}= f(x)$.
  But since $\trans{(\refl{x})}{f(x)}\jdeq f(x)$, we get that $D(x,x,\refl{x})\jdeq (f(x)= f(x))$.
  Thus, we find the term
  \begin{equation*}
    d\defeq\lambda x.\refl{f(x)}:\prd{x:A} D(x,x,\refl{x})
  \end{equation*}
  and now $J$ gives us $\apdfunc f(p):\trans p{f(x)}= f(y)$ for each $p:x= y$.
\end{proof}

\begin{proof}[Second proof]
  By induction, it suffices to assume $p$ is $\refl x$.
  But in this case, we have $\trans{(\refl{x})}{f(x)}\jdeq f(x)$ judgmentally.
\end{proof}

Recall that a non-dependently typed function $f:A\to B$ is just the special case of a dependently typed function $f:\prd{x:A} P(x)$ when $P$ is a constant dependent type, $P(x) \defeq B$.
In this case, $\apdfunc{f}$ and $\apfunc{f}$ are closely related, because of the following lemma:

\begin{lem}\label{thm:trans-trivial}
  If $P:A\to\type$ is defined by $P(x) \defeq B$ for a fixed $B:\type$, then for any $x,y:A$ and $p:x=y$ and $b:B$ we have $\transfib P p b = b$.
\end{lem}
\begin{proof}[First proof]
  Fix a $b:B$, and let $D:\prd{x,y:A}{p:\id{x}{y}} \type$ be the dependent type defined by
  \[ D(x,y,p) \defeq (\transfib P p b = b). \]
  Then $D(x,x,\refl x)$ is $(\transfib P{\refl{x}}{b} = b)$, which is judgmentally equal to $(b=b)$ by the computation rule for transporting.
  Thus, we have the term
  \[ d \defeq \lambda x.\refl{b} : \prd{x:A} D(x,x,\refl x). \]
  Now $J$ gives us a term in $\prd{x,y:A}{p:x=y}(\transfib P p b = b)$, as desired.
\end{proof}
\begin{proof}[Second proof]
  By induction, it suffices to assume $y$ is $x$ and $p$ is $\refl x$.
  But $\transfib P {\refl x} b \jdeq b$, so in this case what we have to prove is $b=b$, and we have $\refl{b}$ for this.
\end{proof}

Thus, by concatenating with the path defined in \autoref{thm:trans-trivial}, for any $x,y:A$ and $p:x=y$ and $f:A\to B$ we have functions
\begin{align}
  \big(f(x) = f(y)\big) &\to \big(\trans{p}{f(x)} = f(y)\big)\label{eq:ap-to-apd}
  \qquad\text{and} \\
  \big(\trans{p}{f(x)} = f(y)\big) &\to \big(f(x) = f(y)\big).\label{eq:apd-to-ap}
\end{align}
In fact, these functions are inverse equivalences (in the sense to be introduced in \S\ref{sec:basics-equivalences}), and they relate $\apfunc f (p)$  to $\apdfunc f (p)$.
But because the types of $\apdfunc{f}$ and $\apfunc{f}$ are different, it is often clearer to use different notations for them.
We may sometimes use a notation $\apd f p$ for $\apdfunc{f}(p)$, which is similar to the notation $\ap f p$ for $\apfunc{f}$.

\begin{thm}[Path lifting property]\label{thm:path_lifting}
Let $P:A\to\type$ be a dependent type over $A$ and assume we have $u:P(x)$ for $x:A$. Then we have the identity
\begin{equation*}
\mathsf{lift}(u,p):(x,u)=(y,\trans{p}{u})
\end{equation*}
in $\sm{x:A}P(x)$ for any $p:x=y$.
\end{thm}

\begin{proof}[First proof]
Let $D:\prd{x,y:A}{p:x=y}\type$ be defined by
\begin{equation*}
D(x,y,p)\defeq (x,u)=(y,\trans{p}{u}).
\end{equation*}
Then $D(x,x,\refl{x})\defeq (x,u)=(x,\trans{\refl{x}}{u})$. By the conversion rule we have $\trans{\refl{x}}{u}\defeq u$, so we see that $D(x,x,\refl{x})\defeq (x,u)=(x,u)$. Therefore we find $d(x)\defeq\refl{(x,u)}:D(x,x,\refl{x})$. Now $J$ gives a term of type $\prd{x,y:A}{p:x=y}(x,u)=(y,\trans{p}{u})$.
\end{proof}
\begin{proof}[Second proof] 
  By induction, it suffices to find a term of type $(x,u)=(x,\trans{\refl{x}}{u})$.
  Note that $\trans{\refl{x}}{u}\jdeq u$, so we really need to find a term of type $(x,u)=(x,u)$.
  But here we can take the reflexivity term.
\end{proof}

\medskip

At this point, we hope the reader is starting to get a feel for proofs by induction on identity types.
From now on we desist from giving both styles of proofs, allowing ourselves to use whatever is most clear and convenient (and often the second, more concise one).


\section{Summary of the basic higher structure}
\label{sec:basics-summary}

Here we summarize the basic definitions made in the previous two sections.

\begin{itemize}
\item $\opp{p} : y=x$, for $p:x=y$, defined by
  \[\opp{\;\refl{x}}\jdeq \refl{x}.\]
\item $p\ct q :y=z$, for $p:x=y$ and $q:y=z$, defined by
  \[ \refl{x}\ct\refl{x}\jdeq\refl{x}.\]
\item If $P$ is a dependent type over $A$ then $\transf{p}:P(x)\ra P(y)$, for $p:x=y$, defined by
  \[\transf{(\refl{x})}\jdeq \idfunc[P(x)].\]
\item If $f:A\ra B$ then $\map{f}{p}:f(x)=f(y)$, for $p:x=y$, defined by
  \[\map{f}{\refl{x}}\jdeq \refl{f(x)}.\]
\item If $f:\prod_{x:A}P(x)$ then $\mapdep{f}{p}:\trans{p}{f(x)}=f(y)$, for $p:x=y$, defined by
  \[\mapdep{f}{\refl{x}}\jdeq \refl{f(x)}.\]
\end{itemize}


\input{basics-equivalences}

\input{computational}


\section{Universal properties}
\label{sec:universal-properties}

By combining the path computation rules described in \S\ref{sec:computational}, we can show that various type forming operations satisfy the expected universal properties.
For instance, given types $X,A,B$, we have a function
\begin{equation}
  (X\to A\times B) \;\to \; (X\to A)\times (X\to B)\label{eq:prod-ump-map}
\end{equation}
defined by $f \mapsto (\proj1 \circ f, \proj2\circ f)$.

\begin{thm}\label{thm:prod-ump}
  \eqref{eq:prod-ump-map} is an equivalence.
\end{thm}
\begin{proof}
  We define a quasi-inverse to send $(g,h)$ to the function $x\mapsto (g(x),h(x))$.
  (Technically, we have used the induction principle for the cartesian product $(X\to A)\times (X\to B)$, to reduce to the case of a pair.)

  Now given $f:X\to A\times B$, the round-trip composite yields the function
  \begin{equation}
    x\mapsto (\proj1(f(x)),\proj2(f(x))).\label{eq:prod-ump-rt1}
  \end{equation}
  By \autoref{thm:path-prod}, for any $x:X$ we have $(\proj1(f(x)),\proj2(f(x))) = f(x)$.
  Thus, by function extensionality, the function~\eqref{eq:prod-ump-rt1} is equal to $f$.

  On the other hand, given $(g,h)$, the round-trip composite yields the pair $(x\mapsto g(x),x\mapsto h(x))$.
  By function extensionaility, the two components of this are equal to $g$ and $h$ respectively, so by \autoref{thm:path-prod}, the pair is equal to $(g,h)$.
\end{proof}

In fact, we also have a dependently typed version of this universal property.
Suppose given a type $X$ and dependent types $A,B:X\to \type$.
Then we have a function
\begin{equation}\label{eq:prod-umpd-map}
  \Big(\prd{x:X} (A(x)\times B(x))\Big) \;\to\; \Big(\prd{x:X} A(x)\Big) \times \Big(\prd{x:X} B(x)\Big)
\end{equation}
defined as before by $f \mapsto (\proj1 \circ f, \proj2\circ f)$.

\begin{thm}\label{thm:prod-umpd}
  \eqref{eq:prod-umpd-map} is an equivalence.
\end{thm}
\begin{proof}
  Left to the reader.
\end{proof}

Just as $\Sigma$-types are a generalization of cartesian products, they satisfy a generalized version of this universal property.
Jumping right to the dependently typed version, suppose we have a type $X$, a dependent type $A:X\to \type$, and a doubly dependent type $P:\prd{x:X} A(x)\to\type$.
Then we have a function
\begin{multline}
  \label{eq:sigma-ump-map}
  \Big(\prd{x:X} \textstyle\sum_{a:A(x)} P(x,a)\Big) \\ \;\to\;
  \Big(\sm{g:\textstyle\prod_{x:X} A(x)} \textstyle\prod_{x:X} P(x,g(x))\Big)
\end{multline}
Note that if we have $P(x,a) \defeq B(x)$ for some $B:X\to\type$, then~\eqref{eq:sigma-ump-map} reduces to~\eqref{eq:prod-umpd-map}.

\begin{thm}\label{thm:ttac}
  \eqref{eq:sigma-ump-map} is an equivalence.
\end{thm}
\begin{proof}
  As before, we define a quasi-inverse to send $(g,h)$ to the function $x\mapsto (g(x),h(x))$.
  Now given $f:\prd{x:X} \sm{a:A(x)} P(x,a)$, the round-trip composite yields the function
  \begin{equation}
    x\mapsto (\proj1(f(x)),\proj2(f(x))).\label{eq:prod-ump-rt1}
  \end{equation}
  Now for any $x:X$, by \autoref{thm:eta-sigma} ($\eta$-equivalence for $\Sigma$-types) we have $(\proj1(f(x)),\proj2(f(x))) = f(x)$.
  Thus, by function extensionality,~\eqref{eq:prod-ump-rt1} is equal to $f$.

  On the other hand, given $(g,h)$, the round-trip composite yields the pair $(x\mapsto g(x),x\mapsto h(x))$.
  But $x\mapsto g(x)$ and $x\mapsto h(x)$ are judgmentally equal to $g$ and $h$, respectively, and hence this pair of functions is also equal to $(g,h)$.
\end{proof}

This is noteworthy because the propositions-as-types interpretation of~\eqref{eq:sigma-ump-map} is ``the axiom of choice''.
If we read $\Sigma$ as ``there exists'' and $\Pi$ (sometimes) as ``for all'', we can pronounce:
\begin{itemize}
\item $\prd{x:X} \sm{a:A(x)} P(x,a)$ as ``for all $x:X$ there exists an $a:A(x)$ such that $P(x,a)$'', and
\item $\sm{g:\prd{x:X} A(x)} \prd{x:X} P(x,g(x))$ as ``there exists a choice function $g:\prd{x:X} A(x)$ such that for all $x:X$ we have $P(x,g(x))$''.
\end{itemize}
Thus, \autoref{thm:ttac} says that not only is the axiom of choice ``true'', it hypotheses are equivalent to its conclusion.
(On the other hand, it should also be clear to the classical mathematician that~\eqref{eq:sigma-ump-map} does not carry the intended meaning of the axiom of choice, since we have specified the values of $g$ already and there are no choices left to be made.
We will return to this point in \S\ref{sec:prop-subset} and [wherever we discuss truncations].)


\section{Sets}
\label{sec:basics-sets}

While types in general behave like higher groupoids, there is a subclass of them that behave more like the sets in a traditional set-theoretic system.
Categorically, we may consider \emph{discrete} groupoids, which are determined by a set of objects and only identity morphisms and higher morphisms, while topologically we may consider sets with the discrete topology.
More generally, we may consider groupoids or spaces that are \emph{equivalent} to ones of this sort; since everything we do in type theory is up to homotopy, we can't expect to tell the difference.

Intuitively, we would expect a type to ``be a set'' in this sense if it has no higher homotopy information: any two parallel paths are equal (up to homotopy), and similarly for parallel higher paths at all dimensions.
Fortunately, because everything in homotopy type theory is automatically functorial/continuous, it turns out to be sufficient to ask this at the bottom level.

\begin{defn}\label{defn:set}
  A type $A$ is a \textbf{set} if for all $x,y:A$ and all $p,q:x=y$, we have $p=q$.
\end{defn}

More precisely, the proposition $\isset(A)$ is defined to be the type
\[ \isset(A) \defeq \prd{x,y:A}{p,q:x=y} (p=q). \]
In Chapter~\ref{cha:hlevels} we will make precise the sense in which this ``suffices for all higher levels'', but as an example, we observe that it suffices for the next level up.

\begin{lem}\label{thm:isset-is1type}
  If $A$ is a set (that is, $\isset(A)$ is inhabited), then for any $x,y:A$ and $p,q:x=y$ and $r,s:p=q$, we have $r=s$.
\end{lem}
\begin{proof}
  Suppose $f:\isset(A)$; then for any $x,y:A$ and $p,q:x=y$ we have $f(x,y,p,q):p=q$.
  Fix $x$, $y$, and $p$, and define $g: \prd{q:x=y} (p=q)$ by $g(q) \defeq f (x,y,p,q)$.
  Then for any $r:q=q'$, we have $\apdfunc{g}(r) : \trans{r}{g(q)} = g(q')$.
  By \autoref{thm:transport-paths}, therefore, we have $g(q) \ct r = g(q')$.

  In particular, suppose given $x,y,p,q,r,s$ as in the lemma statement, and define $g$ as above.
  Then $g(p) \ct r = g(q)$ and also $g(p) \ct s = g(q)$, hence by cancellation we have $r=s$.
\end{proof}

As mentioned in \S\ref{sec:types-vs-sets},
the sets in homotopy type theory are not like the sets in ZF set theory, in that there is no global ``membership predicate'' $\in$.
They are more like the sets used in structural mathematics and in category theory, whose elements are ``abstract points'' to which we give structure with functions and relations.
This is all we need in order to use them as a foundational system for most set-based mathematics; we will see some examples in Chapter~\ref{cha:set-math}.

Which types are sets?
In Chapter~\ref{cha:hlevels} we will study a more general form of this question in depth, but for now we can observe some easy examples.

\begin{eg}
  The type \unit is a set.
  For by \autoref{thm:path-unit}, for any $x,y:\unit$ we have $\eqv{(x=y)}{\unit}$.
  Since any two elements of \unit are equal, this implies that any two elements of $x=y$ are equal.
\end{eg}

\begin{eg}
  The type $\emptyset$ is a set, for given any $x,y:\emptyset$ we may deduce anything we like by contradiction.
\end{eg}

\begin{eg}
  The type \nat of natural numbers is also a set.
  This follows from \autoref{thm:path-nat}, since all equality types $\id[\nat]xy$ are equivalent to either \unit or \emptyt, and any two inhabitants of \unit or \emptyt are equal.
  We will see another proof of this fact in Chapter~\ref{cha:hlevels}.
\end{eg}

Most of the type forming operations we have considered so far also preserve sets.

\begin{eg}\label{thm:isset-prod}
  If $A$ and $B$ are sets, then so is $A\times B$.
  For given $x,y:A\times B$ and $p,q:x=y$, by \autoref{thm:path-prod} we have $p= \pairpath(\projpath1(p),\projpath2(p))$ and $q= \pairpath(\projpath1(q),\projpath2(q))$.
  But $\projpath1(p)=\projpath1(q)$ since $A$ is a set, and $\projpath2(p)=\projpath2(q)$ since $B$ is a set; hence $p=q$.
\end{eg}

\begin{eg}\label{thm:isset-forall}
  If $A$ is \emph{any} type and $B:A\to \type$ is such that for each $x:A$, the type $B(x)$ is a set, then the type $\prd{x:A} B(x)$ is a set.
  For suppose $f,g:\prd{x:A} B(x)$ and $p,q:f=g$.
  By function extensionality, we have $p = {\funext (x \mapsto \happly(p,x))}$ and likewise $q = {\funext (x \mapsto \happly(q,x))}$.
  But for any $x:A$, we have $\happly(p,x):f(x)=g(x)$ and also $\happly(q,x):f(x)=g(x)$, so since $B(x)$ is a set we have $\happly(p,x) = \happly(q,x)$.
  Now using function extensionality again, we conclude that the dependent functions $(x \mapsto \happly(p,x))$ and $(x \mapsto \happly(q,x))$ are equal, and hence (applying $\apfunc{\funext}$) so are $p$ and $q$.
\end{eg}

For more examples, see Exercises~\ref{ex:isset-coprod} and~\ref{ex:isset-sigma}.
However, not all types are sets.

\begin{eg}
  The universe \type is not a set.
  To prove this, it suffices to exhibit a type $A$ and a path $p:A=A$ which is not equal to $\refl A$.
  Take $A=\unit+\unit$, and let $f:A\to A$ be defined by $f(\inl(\ttt))\defeq \inr(\ttt)$ and $f(\inr(\ttt))\defeq \inl(\ttt)$.
  Then $f(f(x))=x$ for all $x$ (by an easy case analysis), so $f$ is an equivalence.
  Hence, by univalence, $f$ gives rise to a path $p:A=A$.

  If $p$ were equal to $\refl A$, then (again by univalence) $f$ would equal the identity function of $A$.
  But this would imply that $\inl(\ttt)=\inr(\ttt)$, contradicting the disjointness of injections from \S\ref{sec:compute-coprod}.
\end{eg}

We will study other types that are not sets in more detail starting in Chapter~\ref{cha:hits}.


\section{Propositions and subsets}
\label{sec:prop-subset}

Just as there are some types which behave more like sets than others, so there are some types which behave more like propositions than others.
In set-theoretic foundations, a proposition can be true or false, but contains no additional data, whereas when we regard a type as a proposition, it can contain many different elements or ``proofs''.
Sometimes this is desirable, but other times we would like to consider only ``propositions'' which carry no additional information beyond a truth value.

In classical mathematics, the truth values ``false'' and ``true'' can be usefully identified with the zero- and one-element sets.
In intuitionistic mathematics, this is no longer true, but we can still identify truth values with sets that have \emph{at most one element}.
Category-theoretically, these sets are called \emph{subterminal objects}; set-theoretically we may call them \emph{subsingletons}.

Thus, in type theory it is natural to consider those types $P$ which are sets (in the sense of \S\ref{sec:basics-sets}) and which furthermore have at most one element, i.e.\ satisfy $\prd{x,y:P} (x=y)$.
However, analogously to how \autoref{defn:set} suffices to collapse all higher homotopy, it turns out to be unnecessary to assume explicitly that such a type is a set.

\begin{defn}
  A type $P$ is a \textbf{mere proposition} if for all $x,y:P$ we have $x=y$.
\end{defn}

More precisely, the type $\isprop(P)$ is defined to be
\[ \isprop(P) \defeq \prd{x,y:P} (x=y). \]
We add the word \emph{mere} when pronouncing this type, because it is common in type theory to allow \emph{arbitrary} types to be regarded as propositions, simply by declaring one's intent to do so.
In proof-relevant mathematics, this is entirely sensible; but it is nevertheless important to know which types are mere propositions.

\begin{thm}\label{thm:isset-prop}
  Every mere proposition is a set.
\end{thm}
\begin{proof}
  Just like \autoref{thm:isset-is1type}.
\end{proof}

Note that a type $A$ is a set if and only if for all $x,y:A$, the identity type $\id[A]xy$ is a mere proposition.
Of course, the types \unit and \emptyt are mere propositions; under classical logic every mere proposition would be equivalent to one of these.
We have seen one other example so far: condition~\ref{item:be3} in \S\ref{sec:basics-equivalences} asserts that for any function $f$, the type $\isequiv (f)$ should be a mere proposition.

One reason it can be helpful to know that a type is a mere proposition is for the construction of \emph{subsets} (and, more generally, subtypes).
Suppose $P:A\to\type$ is a dependent type, with each type $P(x)$ regarded as a proposition.
Then $P$ itself is a \emph{predicate} on $A$, or a \emph{property} of elements of $A$.

In set theory, whenever we have a predicate on $P$ on a set $A$, we may form the subset $\setof{x\in A | P(x)}$.
In type theory, the obvious analogue is the $\Sigma$-type $\sm{x:A} P(x)$.
An inhabitant of $\sm{x:A} P(x)$ is, of course, a pair $(x,p)$ where $x:A$ and $p$ is a proof of $P(x)$.
However, for general $P$, an element $a:A$ might give rise to more than one distinct element of $\sm{x:A} P(x)$, if the proposition $P(a)$ has more than one distinct proof.
This is counter to the usual intuition of a \emph{subset}.
But if $P$ is a mere proposition, then this cannot happen.

\begin{lem}
  Suppose $P:A\to\type$ is a dependent type such that $P(x)$ is a mere proposition for all $x:A$.
  If $u,v:\sm{x:A} P(x)$ are such that $\proj1(u) = \proj1(v)$, then $u=v$.
\end{lem}
\begin{proof}
  Suppose $p:\proj1(u) = \proj1(v)$.
  By \autoref{thm:path-sigma}, to show $u=v$ it suffices to show $\trans{p}{\proj2(u)} = \proj2(v)$.
  But $\trans{p}{\proj2(u)}$ and $\proj2(v)$ are both elements of $P(\proj1(v))$, which is a mere proposition; hence they are equal.
\end{proof}

For instance, recall that in \S\ref{sec:basics-equivalences} we defined
\[(\eqv A B) \;\defeq\; \sm{f:A\to B} \isequiv (f),\]
and that each type $\isequiv (f)$ is a mere proposition.
It follows that if two equivalences have equal underlying functions, then they are equal as equivalences.

A good number of type-forming operations preserve mere propositions, but fewer than preserve sets.

\begin{eg}
  If $A$ and $B$ are mere propositions, so is $A\times B$.
  This is easy to show using the characterization of paths in products, just like \autoref{thm:isset-prod} but simpler.
\end{eg}

\begin{eg}\label{thm:isprop-forall}
  If $A$ is any type and $B:A\to \type$ is such that for all $x:A$, the type $B(x)$ is a mere proposition, then $\prd{x:A} B(x)$ is a mere proposition.
  This is just like \autoref{thm:isset-forall} but simpler: given $f,g:\prd{x:A} B(x)$, for any $x:A$ we have $f(x)=g(x)$ since $B(x)$ is a mere proposition.
  But then by function extensionality, we have $f=g$.

  In particular, if $B$ is a mere proposition, then so is $A\to B$ regardless of what $A$ is.
  In even more particular, since \emptyt is a mere proposition, so is $\neg A \jdeq (A\to\emptyt)$.
\end{eg}

\autoref{thm:isprop-forall} implies that ``being a mere proposition'' is itself always a mere proposition (regardless of whether or not it is \emph{true}).

\begin{cor}
  For any type $A$, the type $\isprop(A)$ is a mere proposition.
\end{cor}
\begin{proof}
  Suppose $f,g:\isprop(A)$; we must show $f=g$.
  Since $A$ is a mere proposition (by, say, $f$), \autoref{thm:isset-prop} implies that $A$ is a set.
  Thus, for every $x,y:A$ the type $x=y$ is a mere proposition, so by \autoref{thm:isprop-forall} (applied twice), the type $\isprop(A)\jdeq \prd{x,y:A}(x=y)$ is also a mere proposition.
  Since $f$ and $g$ are both elements of this type, they are equal.
\end{proof}

On the other hand, some type formers do not preserve mere propositions.
Even if $A$ and $B$ are mere propositions, $A+B$ will not in general be.
As a very special case, \unit is a mere proposition, but $\unit+\unit$ is not, since $\inl(\ttt)$ and $\inr(\ttt)$ are not equal.
Logically speaking, the coproduct $A+B$ is a ``purely constructive'' sort of ``or'', which remembers exactly which disjunct is true.
Sometimes this is very useful, but if we want a more classical sort of ``or'' which does not retain this information, we need an operation which ``truncates'' any type into a mere proposition.
The same issue arises with existential quantification: the $\Sigma$-type $\sm{x:A} P(x)$ is a purely constructive interpretation of ``there exists an $x:A$ such that $P(x)$'' which remembers the witness $x$, and hence is not generally a mere proposition even if each type $P(x)$ is.
We will come back to this in [where?].


\section*{Notes}
\label{sec:notes}

The definition of identity types and the elimination rule $J$ are due to Martin-L\"of (what is the best reference?).
Our identity types are generally called \emph{intensional}, by contrast with the \emph{extensional} case which would have an additional ``reflection rule'' saying that if $p:x=y$, then in fact $x\jdeq y$.
This reflection rule implies that all the higher groupoid structure collapses, so for nontrivial homotopy we must use the intensional version. 
One may argue, however, that homotopy type theory is more ``extensional'' than traditional extensional type theory, because of the function extensionality and univalence rules.  

The proofs of symmetry (inversion) and transitivity (concatenation) for equalities are well-known in type theory.
The fact that these make each type into a 1-groupoid (up to homotopy) is also folklore, and was exploited in~\cite{hs:gpd-typethy} to give the first homotopical semantics for type theory.  The general homotopical interpretation, with identity types as path spaces, is due to \cite{aw:hiit}.
For a construction of \emph{all} the higher operations and coherences of an $\infty$-groupoid in type theory, see~\cite{pll:wkom-type} and~\cite{bg:type-wkom}.

Operations such as $\transfib{P}{p}{-}$ and $\apfunc{f}$ and one good notion of equivalence were first studied extensively in type theory by Voevodsky, using the proof assistant Coq.
Subsequent researchers have found many other equivalent definitions of equivalence, which we will compare in Chapter~\ref{cha:equivalences}.

The ``computational'' interpretation of identity types, transport, and so on described in \S\ref{sec:computational} has been emphasized by~\cite{lh:canonicity}.
They also described a ``1-truncated'' type theory (see Chapter~\ref{cha:hlevels}) in which these rules really are computation steps (that is, definitional equalities which a computer can ``evaluate'').
The possibility of extending this to the full untruncated theory is a subject of current research.

The naive form of function extensionality which says that ``if two functions are pointwise equal, then they are equal'' is a common axiom in type theory.
Some stronger forms of function extensionality were considered in~\cite{garner:depprod}.
The version we have used, which identifies the identity types of function types up to equivalence, was first studied by Voevodsky, who also proved that it is implied by the naive version.

The univalence axiom is also due to Voevodsky.
It was originally motivated by semantic considerations; see~\cite{klv:ssetmodel} [and possibly an appendix, if we include one about semantics].

The simple conclusions in \S\S\ref{sec:compute-coprod}--\ref{sec:compute-nat} such as ``coproduct injections are injective and disjoint'' are well-known in type theory, and the construction of the function \encode is the usual way to prove them.
The more refined approach we have described, which characterizing the entire identity type of a positive type (up to equivalence), is a more recent development; see e.g.~\cite{ls:pi1s1}.

The type-theoretic axiom of choice~\eqref{eq:sigma-ump-map} was first observed to be true by Martin-L\"of.

The fact that it is possible to define sets and (mere) propositions in type theory using finitely many data, with all higher homotopies automatically taken care of as in \S\ref{sec:basics-sets} and \S\ref{sec:prop-subset}, was first observed by Voevodsky.
His original definitions of $\isset$ and $\isprop$ were a bit more complicated than ours, but have the advantage of fitting neatly into an infinite hierarchy; see Chapter~\ref{cha:hlevels}.


\section*{Exercises}
\label{basics:exercises}

\begin{ex}\label{ex:basics:concat}
  Show that the three obvious proofs of \autoref{lem:concat} are pairwise equal.
\end{ex}

\begin{ex}
  Show that the three equalities of proofs constructed in the previous exercise form a commutative triangle.
\end{ex}

\begin{ex}
  Give a fourth, different, proof of \autoref{lem:concat}, and prove that it is equal to the others.
\end{ex}

\begin{ex}
  Prove that the functions~\eqref{eq:ap-to-apd} and~\eqref{eq:apd-to-ap} are inverse equivalences, and that they take $\apfunc f(p)$ to $\apdfunc f (p)$ and vice versa.
\end{ex}

\begin{ex}\label{ex:ap-sigma}
  State and prove a generalization of \autoref{thm:ap-prod} from cartesian products to $\Sigma$-types.
\end{ex}

\begin{ex}
  State and prove an analogue of \autoref{thm:ap-prod} for coproducts.
\end{ex}

\begin{ex}
  Prove that coproducts have the expected universal property:
  \[ \eqv{(A+B \to X)}{(A\to X)\times (B\to X)} \]
  Can you generalize this to an equivalence involving dependent functions?
\end{ex}

\begin{ex}
  Prove that if $\eqv A B$ and $A$ is a set or a mere proposition, then so is $B$.
\end{ex}

\begin{ex}\label{ex:isset-coprod}
  Prove that if $A$ and $B$ are sets, then so is $A+B$.
\end{ex}

\begin{ex}\label{ex:isset-sigma}
  Prove that if $A$ is a set and $B:A\to \type$ is a dependent type such that $B(x)$ is a set for all $x:A$, then $\sm{x:A} B(x)$ is a set.
\end{ex}

\begin{ex}
  A type is called \textbf{contractible} if it is a mere proposition which contains an element.
  That is, we define
  \[ \iscontr(A) \defeq A\times \isprop(A). \]
  Show that $A$ is contractible if and only if it is equivalent to \unit.
\end{ex}

\begin{eg}
  Show that for any type $A$, the type $\isset(A)$ is a mere proposition.
\end{eg}

% Local Variables:
% TeX-master: "main"
% End:
