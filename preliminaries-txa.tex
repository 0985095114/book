\chapter{Type theory}
\label{cha:typetheory}

Before we go on to discuss the specific aspects of Homotopy Type
Theory we will have a look at the basic notions of Type Theory. Keep
in mind that Type Theory is a foundational language, i.e. an
alternative to Zermelo-Fraenkel set theory and at the same time it can
be viewed as a programming language not to dissimilar to modern
functional programming languages like Haskell. In particular the
notion of a type is very different from the notion of a set in set
theory and resembles more the types of strongly typed programming
languages. When we write $3 : \Nat$ then this is a judgement in Type
Theory while the similar looking statement $3 \in \Nat$ in set theory
is a proposition. As a consequence we cannot talk about objects in
isolation of their type. While this may seem to be a restriction at
the first glance it is precisely this aspect which makes the homotopy
interpretation possible.

We attempt here to give an informal presentation of Type Theory,
sufficient for the purposes of this book, more formal accounts can be
found in \cite{hofmann-traktat,...}.

For the purpose of this book we consider two judgements:
\begin{description}
\item[$a : A$] $a$ is an object of type $A$.
\item[$a \equiv_A b$] $a$ and $b$ are definitionally equal 
  objects of type $A$.
\end{description}
Judgements may depend on assumptions of the form $x:A$ where $x$ is a
variable and $A$ is a type. As an example we may
construct an object $m + n : \Nat$ under the assumptions that $m,n :
\Nat$. Another example is that we assume that $A $ is a type, $x,y : A$ and
$p : x =_A y$ and from this we construct $p^{-1} : y =_A x$. Here we
use types to represent propositions whose inhabitants are proofs. We
may omit the names of proofs and instead say that from $x =_A y$ we
can infer $y =_A x$ but since we are doing proof-relevant mathematics
we will frequently refer back to proofs as objects, e.g. in this case
we may want to establish that $p^{-1}$ together with the proofs of
transitivity and reflexivity behave like a group or more precisely a
groupoid.

We emphasize the difference between equality type $a =_A
b$ and the judgment $a \jdeq_A b$. The statement $a =_A b$ requires a
proof, i.e. the construction of an inhabitant $p : a =_A b$. In
contrast $a \jdeq b$ can be decided mechanically just by expanding
definitions. So if we define $c \defeq 1$ then $c\jdeq 1$. Another
source of definitional equality is the application of a function. If
we define a function $f : \Nat \to \Nat$ as $f(n) \defeq n + n$ then
$f(3) \jdeq 3+3$ (this corresponds to $\beta$-equality in
$\lambda$-calculus). As for $a : A$ the judgement $a \jdeq b$
cannot be used within a proposition. In particular  $a
\jdeq b \to b \jdeq a$ is not a proposition (i.e. a type) in type theory. In
contrast if $a =_A b \to b =_A a$ is a type and hence a proposition.

Given a type $A$, if from assuming $x:A$ we can deduce $B[x]$ is a type.
Here we write $B[x]$ to make it clear that $B$ may contain the
variable $x$ then we say $B[x]$ is a
family of types in $\UU$ indexed by $x:A$. An example is the type $Vec(A,n)$ of
vectors ($n$-tuples) of elements of type $A$ which is family indexed
over $n : \Nat$. Another example is the type $x =_A x$ which is a
family indexed over $x : A$.

We now introduce the basic type formers of Type Theory.

\section{Universes}
\label{sec:universes}

We introduce a sequence of symbols $\UU_0,\UU_1,\UU_2, \dots$ which
stand for type theoretic universes, i.e. types whose elements are
types. In a way it would be nice if we just had one universe $\UU$ of
all types including $\UU : \UU$. However, we can encode Russell's
paradox in Type Theory and such a universe makes the type theory
inconsistent (every type is inhbited). Instead we introduce a
hierarchy of universes
\[ \UU_0 : \UU_1 : \UU_2 : \dots \]
We assume that the hierarchy of universes is cummulative, i.e. if
$A:\UU_i$ then $A : \UU_{i+1}$. Hence the difference between
$\UU_0$ and $\UU_1$ is that $\UU_1$ contains the type $\UU_0:\UU_1$
types build from $\UU_0$. Similarily $\UU_2$ contains all the types
from $\UU_1$ and additionally $\UU_1$ and types build using $\UU_1$. 

We say that our type theory is predicative if types in a universe
$\UU_i$ are introduced only with reference to types in the same or
lower universes. Most (all ?) constructions introduced in this book
are predicative. 

When we say $A$ is a type we mean that it is an element of some
universe $\UU_i$. To avoid having to clutter up the text with indices
we use the metavariable $\UU$ to stand for any universe. That is $A$
is a type is the same as saying $A : \UU$.

\section{The dependent function types ($\Pi$-types)}

Functions are a primitive concept in Type Theory, they are not reduced
to relations as in set theory. The dependent function type is a
generalisation of non-dependent function type $A \to B$ which allow
the codomain to vary over the codomain over the domain. Thus using the
proposition as types principle we can use function types to model not
only implication but also universal quantification. Given a type $A$
and a family $B[x]$ indexed over $x:A$ we can form the type
$\Pi_{x:A}B[x]$ of dependent functions. Non dependent-functions arise
in the special case when $B$ is a constant family (i.e. $B$ does not
dependent on $x$) in which case we write $A \to B$.

Given a dependent function $f : \Pi_{x:A}B[x]$ and $a : A$ we can
apply $f$ to $a$ which we write as $f(a) : B[a]$.  Such a function $f$ may be introduced by a defining equation
  \[ f(x)\defeq b[x]\mbox{ for } x:A,\]
where $b[x]$ is a term for an object of type $B(x)$ for $x:A$ that may depend on the variable $x$ ranging over objects of $A$.  So if $a$ is a term for an object of type $A$ we may substitute $a$ for $x$ in the defining equation to give a definitional equality
  \[ f(a)\jdeq b[a]:B[a]\]
and we have $f(a):B[a]$.  As usual we use the lambda abstraction notation 
$\lambda_{x:A}b[x]$ to name the function $f$ so that if $a:A$ then
  \[\lambda_{x:A}b[x](a)\jdeq b[a]: B(a).\]

Assuming $a:A$ an example of a dependent function of type $\Pi_{n:\Nat}Vec(A,n)$
is the function which constructs an $n$-tuple of $a$s. Another example
of a dependent function is the proof of reflexivity which has the type
$\Pi_{x:A}x = x$.

Dependent function types are used to represent:
\begin{itemize}
\item Conventional (non-dependent) functions as in $\Nat \to \Nat$,
\item Implication as in $x =_A y \to y =_A x$,
\item Universal quantification as in $\Pi_{n:\Nat}m+0 =_\Nat m$.
\end{itemize}

\section{The dependent pair types ($\Sigma$-types)}

As before in the case of functions the dependent pair type is a
generalisation of the ordinary cartesian product $A \times B$. 
As in the case of $\Pi$ we assume that $B[x]$ is a family indexed by
$x:A$ to form $\Sigma_{x:A}B[x]$. Elements of $\Sigma_{x:A}B[x]$ are
pairs $(a,b) : \Sigma_{x:A}B[x]$ where $a:A$ and $b:B[a]$. If the
family $B$ does not depend on $A$ we write $A \times B$.

If $C$ is a family of types on $p:\Sigma_{x:A}B(x)$ and 
$c:\Pi(x:A)(y:B(x)),C((x,y))$ then we may define 
$f:(\Pi z:\Sigma_{x:A}B(x))C(z)$ with defining equation
  \[f((x,y))\defeq c(x)(y)\mbox{ for } x:A,y:B(x).\]

As special cases we can derive the projections: to derive the 1st
projection let $C_1(p) \defeq A$ be the constant family and $c_1 : \Pi (x:A)(y:B(x),A$
defined as $c_1(x)(y) \defeq x$ to derive $\pi_1 : \Sigma_{x:A}B(x)) \to A$
with the defining equation $\pi_1 (x,y) \defeq x$. To derive the 2nd
projection we use $C_2(p) \defeq B (\pi_1(p))$ and $c_2 : \Pi
(x:A)(y:B(x)),B(\pi_1(x,y))$ note that the codomain $B(\pi_1(x,y))$ is
definitionally equal to $B(x)$ and hence we can use $c_2(x)(y) \defeq
y$ to construct $\pi_2 : \Pi(p : \Sigma_{x:A}{B(x)}),B(\pi_1 p)$ with
the defining equation $\pi_2(x,y) \defeq y$.

As an example consider the type $\Sigma_{n:\Nat}Vec(A,n)$ of tuples of
arbitrary length - this type is equivalent to the type of lists or
finite sequences over $A$. Another example is the type
$\Sigma_{n:\Nat}n+n = n$ which expresses the (true) proposition that
there exists a natural number which is equal to its doubling.

A more involved example is the type-theoretic axiom of choice. Assume
there are types $A,B$ and a family $R(x,y)$ indexed over $x:A$ and
$y:B$. Then we can show that from assuming 
\[p : \Pi(x:A)\Sigma(y :B),R(x,y)\] 
we can define 
\begin{eqnarray*}
a(p) & : & \sm{f : A \to B} \prd{x:A} R(x,(fx)) \\
a(p) & \defeq & (\lambda_{x:A} \pi_1(p(x)),\lambda_{x:A} \pi_2(p(x)))
\end{eqnarray*}

Dependent pair types are used to represent:
\begin{itemize}
\item Conventional (non-dependent) pairs as in $\Nat \times \bool$,
\item Conjunction as in $x =_A y \times y =_A z$,
\item Existential quantification as in $\Sigma_{n:\Nat}n+n = n$.
\end{itemize}

\section{Finite types}
\label{sec:finite-types}

We use $\emptyt$, $\unit$ and $\bbB$ for the standard {\bf empty
  type}, the standard {\bf singleton type} and the standard {\bf
  boolean type}, respectively.  So $\emptyt$ is not intended to have
any elements, we have $\star:\unit$ and $0_\bool,1_\bool:\bool$.
\begin{itemize}
\item If $C$ is a family on $\emptyt$ then we have $f:\Pi_{z:\emptyt}(z)$ with no defining equation.
\item If $C$ is a family on $\unit$ and $c:C(\star)$ then we have $f:\Pi_{z:\unit}(z)$ with defining equation
  \[ f(\star)\defeq c.\]
\item If $C$ is a family on $\bool$, $c_0:C(0_\bool)$ 
and $c_1:C(1_\bool)$ then we have $f:\Pi_{z:\bool}C(z)$ with the defining equations
 \[ \begin{array}{rl}
f(0_\bool) \defeq& c_0, \mbox{ and}\\
f(1_\bool) \defeq& c_1.
  \end{array}\]
\end{itemize}

If $A$ and $A'$ are types then $A+A'$ is their disjoint union.  If
$a:A$ then there is a copy $\inl(a):A+A'$ and if $a':A'$ there is a
copy $\inr(a'):A+A'$.
If $C$ is a family on $A+A'$, $c_\inl:\Pi_{x:A}C(\inl(x))$ and $c_\inr:\Pi_{x':A'}C(\inr(x'))$ then $f:\Pi_{z:A+A'}C(z)$ with defining equations
  \[\left\{\begin{array}{rll} 
f(\inl(x))\defeq& c_\inl(x)&\mbox{ for } x:A \mbox{ and}\\
f(\inr(x'))\defeq& c_\inr(x')&\mbox{ for } x':A'\\
\end{array}\right.\]

We can define the disjoint union of two types $A,B:\UU$ as
\[A + B \defeq \Sigma_{x:\bool}F(x)\]
where $F : \bool \to \UU$ is
defined as $F(0_\bool) \defeq A$ and $F(1_\bool)\defeq B$. The
injections can be defined as:
\begin{align*}
& \inl :  A \to A+B\\
& \inl(a) \defeq (0_\bool,a)
& \inr :  B \to A+B\\
& \inr(b) \defeq (1_\bool,b)
\end{align*}

\textbf{Todo:} Derive eliminator.

Clearly, using $+$, $0$ and $1$ we can define all finite types.

Our technique to derive $+$ from $\Sigma$ can also be used to derive
$\times$ form $\Pi$ namely given $A,B:\UU$ we can define 
\[ A \times B \defeq \Pi_{x:\bool}F(x)\]
where $F$ is defined as for $+$ above. The projections can be derived
by applications to $0_\bool$ and $1_\bool$. However, the general
eliminator requires the principle of functional extensionality which
we haven't introduced yet. Hence there are two ways to derive $A\times
B$ : either as a non-dependent $\Sigma$-type or as a special case of
$\Pi$ where the domain is boolean. 

\section{The identity types on a type}
If $A:\UU$ is a type and $a,a':A$ then $a =_A a'$ is the identity type on $A$.  
In constructive intensional type theory objects in this type are
intended to represent proofs of the proposition that $a$ and $a'$ are
identical.  So, in particular there is an object $\refl{a}: a =_A a'$ whenever $a:A$.  In Homotopy Type Theory, when $A$ is understood as a space and $a,a'$ are understood as points of the space the type $Id_A(a,a')$ is to be understood as the type of paths from the point $a$ to the point $a'$.

We now give two rules for defining functions on paths, both of which are useful.  Given the other rules of our type theory, when suitably understood, each rule can be derived from the other. 

\begin{description}
\item[Martin-L\"{o}f Rule:] Let $Path_A$ be the type $\Sigma_{x,x':A}Id_A(x,x')$, let $C$ be a family on $Path_A$ and let $c:\Pi_{x:A}C(x,x,\refl{x})$.  Then we have $f:\Pi_{u:Path_A}C(u)$ with defining equation
  \[ f(x,x,\refl{x})\defeq c(x)\mbox{ for } x:A.\]
\item[Paulin-Mohring Rule:] If $a:A$ let $Path_A(a)$ be the type $\Sigma_{y:A}Id_A(a,y)$, let $C$ be a family on $Path_A(a)$ and let $c:C(a,\refl{a})$. Then we have\\ $f:\Pi_{u:Path_A(a)}C(u)$ with defining equation
    \[ f(a,\refl{a})\defeq c.\]
\end{description}

We are going to use the Paulin-Mohring rule to show that $=$ is an
equivalence relation. Assuming a type $A$ we show that there is a function
$p^{-1} : b = a$ given $p : a = b$ using the family $b = a$ and
the defining equation
\[ (\refl{a})^{-1} = \refl{a} \]
Similarily we can show transitivity: assume there is $p : a = b$ and
we want to derive $p \ct - : b = c \to a = b$ by
\[ p \ct \refl{b} \defeq p.\]
Since we already have the constructor $\refl{}$ we have shown that $=_A$
is an equivalence relation. 


\textbf{Todo:} Derive transport and ap.

\section{Inductive types}
The paradigm example of an inductive type is the type $\nat$ of unary natural numbers.  These objects of type $\nat$ are generated from the natural number $0$ by repeatedly applying the successor operation.  So we say that there are two {\bf introduction rules} for $\nat$. 
  \[ 0:\nat\]
and
  \[ \mbox{ from $n:\nat$ infer $\suc(n):\nat$}.\]
The inductive character of $\nat$ is captured by the, so called, elimination and computation rules for $\nat$.  We prefer to call them the rules for defining a function on $\nat$ by primitive recursion. 

If $C$ is a family on $\nat$, $c_0:C(0)$ and $c_\suc(x,y):C(\suc(x))$ for $x:\nat,y:C(x)$ then we may introduce a function $f:\Pi_{x:\nat}C(x)$ by the following primitive recursion defining equations; one defining equation for each introduction rule.

  \[\left\{\begin{array}{rl}
f(0)\defeq& c_0, \mbox{ and}\\
f(\suc(x))\defeq& c_\suc(x,f(x))\mbox{ for } x:\nat
  \end{array}\right.\]

As an example we define the function $m + - : \nat \to \nat$ for any
$m : \nat$ using the constant family $\nat$ and the defining
equations:
\begin{eqnarray*}
  m + 0 & \defeq & m \\
  m + \suc(n) & \defeq & \suc(m + n)
\end{eqnarray*}
By abstracting $m$ using the rules for $\Pi$-types we can derive the
binary function $- + - : \nat \to (\nat \to nat)$.

We use the same principle to prove properties by induction. While it
is trivial to see that $+$ is right neutral because $m + 0 \jdeq m$
we need to prove that $0 + m =_\Nat m$ is inhabited. We do this by
constructing a function $f : \Pi_{n : \nat} 0 + n =_\Nat n$. 
The family is $0 + n =_\Nat n$ over $n : \Nat$. In the case
for $0$ we have that $0 + 0 \jdeq 0$ hence we can define
\[ f(0) \defeq \refl{0} \]
For $\suc(n)$ we have that $0 + \suc(n) \jdeq \suc(0 +
n)$ hence we define 
\[ f(\suc(n)) \defeq \mapfunc{\suc}(f(n)). \]
In this case we can show that the type is propositional, that is that
all elements of the type are equal. In this situation we may omit any
explicit reference to proof objects and the type-theoretic proof does
not look different to a conventional one in predicate logic. 

% Local Variables:
% TeX-master: "main"
% End:
