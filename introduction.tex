\chapter*{Introduction}
\label{cha:introduction}

\addcontentsline{toc}{chapter}{Introduction}

{%%%%%%% macros local to this file, discharged at the end of the file

%\newcommand{\stype}{{\;\sf type}}
%%\newcommand{\nat}{\mathbb{N}}
%\newcommand{\nat}{{\bf N}}
%\newcommand{\rec}{{\sf rec}}
%%\newcommand{\bool}{\bbB}
%\newcommand{\bool}{{\bf B}}
%\newcommand{\app}{{\sf app}}
%\newcommand{\pair}{{\sf pair}}
%\newcommand{\suc}{{\sf succ}}
%\newcommand{\inleft}{{\sf inleft}}
%\newcommand{\inright}{{\sf inright}}
%%\newcommand{\bbzero}{{0\hspace*{-4pt} 0}}
%\newcommand{\emptyt}{{\bf 0}}
%%\newcommand{\bbone}{{1\hspace*{-4pt} 1}}
%\newcommand{\unitt}{{\bf 1}}

\newcommand{\UU}{{\mathcal U}}
\newcommand{\idtypevar}{{{\sf Id}}}
\newcommand{\eq}{{{\sf Eq}}}


%%% Outline
%%	- The idea of HoTT and the special role of Identity

%
%%	- The idea of informal type theory
%
%%	- Brief history - ok
%
%%	- Constructive math vs. general: no proof by contradiction/ proof relevance/ -- still need to do
%
%%	- How is type theory different from set theory? - ok
%
%%	- How is HoTT different from type theory? -ok
%
%%	- Different readers of these notes: -ok 
%%		- Working mathematicians
%%		- ... CS
%%		- ... Logicians
%%		- homotopy theorists and higher category theorists
%
%%	- weak points and work to do -- still needs to be done
%
%%	- Coq development, new proof assistant, etc. - ok
%%

Homotopy type theory is a new field of mathematics combining aspects of several different areas in a surprising way.  It is based on a recently discovered connection between homotopy theory, a branch of algebraic topology, and type theory, a branch of mathematical logic and theoretical computer science.  Although currently the focus of intense investigation, it is increasingly clear that these connections are just the beginning of a subject that will take more time and more hard work to fully understand.  It touches on topics as seemingly distant as the homotopy groups of  spheres and the decidability of type checking algorithms for computational proof assistants.  It includes a new definition of a weak $\infty$-groupoid and a new axiom at the very foundation of mathematics -- Voevodsky's subtle and beautiful Univalence Axiom.  One consequence of that axiom is that isomorphic structures are logically identical, a principle that mathematicians have been happily using on workdays, despite its incompatibility with the ``official" doctrines of conventional foundations.  Another application is in working smoothly with higher inductive types, which provide direct, logical descriptions of some of the basic spaces and constructions of topology: spheres, cylinders, truncations, etc., permitting an entirely new kind of ``logic of homotopy types".   Add in the ever-improving  implementations of type theory in computer proof assistants, and we arrive at a new conception of foundations of mathematics, with intrinsic homotopical content, an ``invariant" conception of the objects of mathematics, and a machine implementation which can serve as a practical aid to the working mathematician.  This is the \emph{univalent foundations program}, and this book is intended as a first systematic exposition of its basics, and an example of this new style of reasoning. 


\subsection*{Type theory}

Type theory was originally invented by Bertrand Russell in 1908 \cite{Russell:1908}, as a device for blocking the paradoxes in the logical foundations of mathematics  that were under investigation at the time. It was later developed as a rigorous formal system  in its own right (under the name ``$\lambda$-calculus") by Alonzo Church \cite{Church:1933cl,Church:1940tu,Church:1941tc}.  Although it is not generally regarded as the foundation for classical mathematics, set theory being more customary, type theory still has numerous applications, especially in computer science and the theory of programming languages \cite{Pierce:2002tp}.   Per Martin-L\"{o}f \cite{MartinLof:1998tw,MartinLof:1975tb,MartinLof:1982bn,MartinLof:1984tr}, among others,
developed a generalization of Church's system which is now usually called dependent, constructive, or simply {\bf Martin\--L\"of type theory}; this is the basis of the system that we consider here. It was originally intended as a rigorous framework for the formalization of constructive mathematics.  

%Over the last 40 years it has also become clear that there are close connections between type theory and category theoretic approaches to logic and foundations, particularly topos theory \cite{elephant}

In type theory, unlike set theory, objects are classified using a primitive notion of \emph{type}, similar to the data-types used in programming languages.  These elaborately structured types can be used to express detailed specifications of the objects classified, giving rise to principles of reasoning about these objects.  To take a very simple example, the objects of a product type $A\times B$ are known to be of the form $\langle a, b\rangle$, and so one automatically knows how to construct them and how to decompose them. Similarly, an object of function type $A\to B$ can be acquired from an object of type $B$ parametrized by objects of type $A$, and can be evaluated at an argument of type $A$.  This rigidly predictable behavior of all objects (as opposed to set theory's more liberal formation principles, allowing inhomogeneous sets) is one aspect of type theory that has led to its extensive use in verifying the correctness of computer programs.  The clear reasoning principles associated with the construction of types also form the basis of modern {\bf computer proof assistants}, which are used for formalizing mathematics and verifying the correctness of formalized proofs.  We return to this aspect of type theory below.  

%(From the point of view of category theory, this is like saying that a product is determined by its universal property.)

%For example, the powerful Coq proof assistant \cite{coq} has recently been used to formalize and verify the correctness of the proof of the celebrated Feit-Thompson Odd-Order theorem \cite{gonthier}.

One problem with understanding type theory from a mathematical point of view, however, has always been that the basic concept of \emph{type} is unlike that of \emph{set} in ways that have been hard to make precise. This difficulty, we believe, has now been solved by the idea of regarding types, not as strange sets (perhaps constructed without using classical logic), but as spaces or, more precisely, as homotopy types of spaces.

In homotopy theory one is concerned with spaces and continuous mappings between them, 
up to homotopy; a \emph{homotopy} between a pair of continuous maps $f \colon X	\to Y$
and  $g \colon X	\to Y$ is 
a continuous map $H \colon X \times [0, 1]	\to Y$ satisfying
$H(x, 0) = f (x)$  and $H(x, 1) = g(x)$. The homotopy $H$ may be thought of as a ``continuous deformation" of $f$ into $g$. The spaces $X$ and $Y$ are said to be \emph{homotopy equivalent}, $X\simeq Y$, if there are continuous maps going back and forth, the composites of which are homotopical to the respective identity mappings, i.e., if they are isomorphic ``up to homotopy".  Homotopy equivalent spaces have the same algebraic invariants (e.g., homology, or the fundamental group), and are said to have the same \emph{homotopy type}.

\subsection*{Homotopy type theory}

Homotopy type theory (``HoTT") is a new field of mathematics which interprets type theory from a homotopical perspective.
In homotopy type theory, one regards the types as spaces, or homotopy types, and the logical constructions (such as the product $A\times B$) as homotopy-invariant constructions on spaces.   In this way, one is able to manipulate spaces directly without first having to develop point-set topology.
To briefly explain this perspective, consider first the basic concept of type theory, namely that
the \emph{term} $a$ is of \emph{type} $A$, which is written:
$$
  a:A.
$$
This expression is traditionally thought of as akin to:
\begin{center}
``$a$ is an element of the set $A$."
\end{center}
However, in HoTT we think of it instead as:
\begin{center}
``$a$ is a point of the space $A$."
\end{center}
Similarly, every term $f : A\to B$ in type theory is regarded as a continuous function from the space $A$ to the space $B$. This perspective clarifies features of type theory which were puzzling from the perspective of types as sets; for instance, that one can have non-trivial types $D$ such that $D\cong (D\to D)$.  But the key new idea of the homotopy interpretation is that the logical notion of identity $a = b$ of two objects $a, b: A$ of the same type $A$ can be understood as the existence of a \emph{path} $p : a \leadsto b$ from point $a$ to point $b$ in the space $A$.  This also means that two functions $f, g: A\to B$ are identical just in case they are homotopic, since a homotopy is just a family of paths $p_x: f(x) \leadsto g(x)$ in $B$, one for each $x:A$.  In type theory, for every type $A$ there is a (formerly somewhat mysterious) type $\idtypevar_{A}$ of identities between objects of $A$; in HoTT, this is just the \emph{path space} $A^I$ of all continuous maps $I\to A$ from the unit interval.  In this way, a term $p : \idtypevar_{A}(a,b)$ represents a path $p : a \leadsto b$ in $A$. 

The idea of homotopy type theory arose around 2006 in independent work by Awodey and Warren (\cite{AW}) and Voevodsky (\cite{VV}), but it was inspired by 
Hofmann and Streicher's earlier groupoid interpretation~\cite{HofmannM:gromtt}.  Indeed, there is a precise sense in which HoTT relates type theory not only to homotopy theory, but also to higher-dimensional category theory, and in particular to weak $\infty$-groupoids --- corresponding to the close connections between those two subjects now under investigation in algebraic topology, and following the course proposed by Grothendieck.  For instance, the approach of Awodey and Warren uses the machinery of Quillen model categories, but Voevodsky's model of type theory uses Kan simplicial sets, which are one concept of $\infty$-groupoids.  Voevodsky recognized that this simplicial interpretation satisfies a further crucial property, dubbed \emph{univalence},  which is not usually assumed in type theory.  Adding univalence  to type theory in the form of a new axiom has far-reaching consequences, many of which are natural, simplifying and compelling.  The Univalence Axiom also further strengthens the homotopical view of type theory, since it holds in the simplicial model, while failing in the view of types as sets.  

\subsection*{Univalent Foundations}

Very briefly, the basic idea of the Univalence Axiom can be explained as follows.  In type theory, one can have a universe $\UU$, the terms of which are themselves types, $A : \UU$, etc.  Of course, we do not have $\UU:\UU$, so only some types are terms of $\UU$ -- call these the \emph{small} types.  Like any type, $\UU$ has an identity type $\idtypevar_{\UU}$ which expresses the identity relation $A = B$ among small types.  Thinking of  types as spaces, $\UU$ is a space, the points of which are spaces; to understand its identity type, we must ask, what is a path $p : A \leadsto B$ between spaces in $\UU$?  The univalence axiom says that such paths correspond to homotopy equivalences $A\simeq B$, (roughly) as explained above.  A bit more precisely, given any (small) types $A$ and $B$, in addition to the type $\idtypevar_{\UU}(A,B)$ of identities between $A$ and $B$ there is the type $\eq(A,B)$ of equivalences from $A$ to $B$.  Since the identity map on any object is an equivalence, there is a canonical map,
$$\idtypevar_{\UU}(A,B)\to\eq(A,B).$$
The univalence axiom states that this map is itself an equivalence.  At the risk of oversimplifying, we can state this succinctly as follows:

\begin{description}
\item[Univalence Axiom:]  $(A = B)\ \simeq\ (A\simeq B)$.
\end{description}
%
In other words, identity is equivalent to equivalence. 

From the homotopical point of view, this says that the universe $\UU$ is something like a classifying space for (small) homotopy types, which is a practical and natural assumption.  From the  logical point of view, however, it is revolutionary: it says that isomorphic things are identical!  Mathematicians are of course used to identifying isomorphic structures in practice, but they generally do so with a wink, knowing that the identification is not ``officially" justified by foundations.  But in this new foundational scheme, not only are such structures formally identified, but the different ways in which such identifications may be made themselves form a structure that one can (and should!) take into account.

%Voevodsky has christened this new foundational scheme, consisting of the combination of homotopy type theory with the univalence axiom, and possibly some further logical principles, together with an implementation in a computer proof assistant, the {\bf Univalent Foundations of Mathematics}.

\subsection*{Informal type theory}

One difficulty often encountered by the classical mathematician when faced with learning about type theory is that it is usually presented as a fully or partially formalized deductive system.  This style, which is very useful for proof-theoretic investigations, is not particularly convenient for use in applied, informal reasoning, nor is it even familiar to most working mathematicians, even those who might be interested in foundations of mathematics.  One objective of the present work is to develop an informal style of working \emph{in} HoTT that is at once rigorous and precise, but is also closer to the language and style of presentation of everyday mathematics.    In mathematics, one usually constructs and reasons about mathematical objects in a way that could in principle, one presumes, be formalized in a system of elementary set theory like ZFC -- at least given enough ingenuity and patience.  For the most part, one does not even need to be aware of this possibility, since it largely coincides with the condition that a proof be fully rigorous.  But there are a few aspects of working in ``informal set theory" that one does need to learn to be careful about: the use of collections too large or inchoate to  be sets, the axiom of choice and its equivalents,  the method of proof by contradiction, and so on.  Adopting a new foundational system such as HoTT as the \emph{implicit formal basis} of informal reasoning will require adjusting some of ones instincts and practices, even when reasoning informally.  The present text is intended to serve as an example of this ``new kind of mathematics", which is still informal, but could now in principle be formalized in HoTT, rather than ZFC, again given enough ingenuity and patience.

It is worth emphasizing that in the new system, however, such formalization has a real practical benefit, increasing the likelihood that one will actually want to carry it out; namely, the implementation of the formal system in a computer proof assistant.  In practical terms, this means that it is possible to use currently available proof assistants based on type theory to develop mathematics, to verify the correctness of proofs, to provide some degree of automation, and even to extract numerical algorithms from formal proofs.  We believe that this aspect of the univalent foundations program distinguishes it from other approaches to foundations, by providing a real practical utility for the working mathematician. Indeed, many of the results given here were actually \emph{first} done in a fully formalized form in a proof assistant, and are only now being ``unformalized" for the first time -- a reversal of the usual relation between formal and informal mathematics.   One can imagine a not too distant future when it will be possible for mathematicians  to verify the correctness of their own papers by working within the system of univalent foundations, formalized in a proof assistant, and that doing so will become as natural as typesetting their own papers in Tex. (Whether this proves to be the publishers' dream or their nightmare  remains to be seen.) 

%We refer the reader to \cite{Simpson:2004bt,Hales:2008ud} for two accounts of the use of computer proof assistants in general.   


\subsection*{Constructivity} 


One of the most striking differences between classical foundations and type theory is the idea of \emph{proof relevance}, according to which mathematical statements, and even their proofs, become first-class mathematical objects.  In type theory, one represents mathematical statements by types, which can be regarded simultaneously as both mathematical constructions and mathematical assertions, a conception also known as \emph{propositions as types}.  Accordingly, a term $a : A$ can be regarded as both an element of the type $A$ (or in HoTT, a point of the space), and at the same time, a proof of the proposition $A$.  To take an example, suppose we have sets $A$ and $B$ (discrete homotopy types), and consider the statement ``$A$ is isomorphic to $B$."  In type theory, this can be rendered as:
\[
\mathsf{Iso}(A,B)\ :=\ \Sigma_{f : A\to B}\Sigma_{g : B\to A}\big((\Pi_{x:A}\, gf(x) = x) \times (\Pi_{y:B}\, fg(y) = y)\big)
\]

Reading the type constructors $\Sigma, \Pi, \times$  here  as ``there exists'', ``for all", and ``and" respectively yields the usual formulation of ``$A$ and $B$ are isomorphic"; on the other hand, reading them as sums and products yields the \emph{type of all isomorphisms} between $A$ and $B$ !  To prove that $A$ and $B$ are isomorphic, one  constructs a proof $p : \mathsf{Iso}(A,B)$, which is therefore the same  as constructing an isomorphism between $A$ and $B$, i.e., exhibiting a pair of functions $f, g$ together with \emph{proofs} that their composites are the respective identity maps.  The latter proofs, in turn, are nothing but homotopies of the appropriate sorts.  In this way, \emph{proving a proposition is the same as constructing a term of some particular type.}

In particular, to prove a statement of the form ``$A$ and $B$" is just to prove $A$ and to prove $B$, i.e., to give a term of type $A\times B$.  And to prove that $A$ implies $B$ is just to find a term $A\to B$, i.e., a function from $A$ to $B$ (determining a mapping of proofs of $A$ to proofs of $B$).  This ``constructive" conception is what gives type theory its good computational character, for every proof that something exists, for example, carries with it enough information to actually find such an object; and from a proof that  ``$A$ or $B$" holds, one can obtain either a proof that $A$ holds or one that $B$ holds.  

Among other things, this conception has the advantage that the {\bf axiom of choice} becomes a provable principle of reasoning: the type theoretic notion of ``there exists" is strong enough to ensure that, if for every $x: A$ there exists a $y:B$ such that $R(x,y)$, then there is a function $f : A\to B$ such that, for all $x:A$, we have $R(x, f(x))$.  On the other hand, the conception of ``or" is so strong that the usual {\bf law of excluded middle} fails: for if we always had a proof of ``$A$ or not $A$", then for \emph{every} proposition $A$ we would either have a proof of it or a refutation -- which would of course be nice, but is unfortunately not the case.  This implies in particular that the usual method of \emph{proof by contradiction} cannot in general be used to establish a positive statement, but only one of the form ``it's not the case that ...".  

Thus the general logic of ``proposition as types" is not classical; however, it is not exactly the usual ``intuitionistic" logic either, since it does have (for example) the axiom of choice.  This combination, sometimes called ``constructive logic", differs from those others in interesting and subtle ways.  One very recent contribution of HoTT is the discovery by Voevodsky of the different levels of so-called \emph{homotopy $n$-types}, which are logically definable classes of types that behave more like logical propositions, sets, $1$-truncated spaces, and so on.  Recognition of this hierarchy leads to a much finer analysis of the relation between logic and type theory than the propositions-as-types conception, and its further investigation is one of our objects of study.

We summarize the different points of view of the type-theoretic operations in the following table.

\begin{center}
  \begin{tabular}{c|c|c|c}
  	Type Theory & Logic & Set Theory & HoTT\\\hline
  	$A$ & proposition & set & space\\
	$a:A$ & proof & element & point \\
    	$x:A \vdash B(x)$ & predicate & family of sets & fibration \\
    	$x:A \vdash b(x) : B(x)$ & conditional proof & family of elements & section\\
	$0, 1$ & $\bot, \top$ & $\emptyset, \{ \emptyset \}$ & $\emptyset, *$\\
	$A + B$ & $A\vee B$ & disjoint union & coproduct\\
	$A\times B$ & $A\wedge B$ & set of pairs & product space\\
	$A\to B$ & $A\Rightarrow B$ & set of functions & function space\\
	$\Sigma_{x:A}B(x)$ &  $\exists_{x:A}B(x)$ & disjoint sum & total space\\
	$\Pi_{x:A}B(x)$ &  $\forall_{x:A}B(x)$ & product & space of sections\\
	$\mathsf{Id}_{A}$ & identity relation & $\{\langle x,x\rangle\, |\, x\in A\}$ & path space $A^I$
  \end{tabular}
\end{center}


\subsection*{Open problems} 

For those interested in contributing to this new branch of mathematics, it may be encouraging to know that there are many interesting open questions.  Perhaps the most pressing of them is the ``constructivity'' of the Univalence Axiom, posed by Voevodsky in \cite{Vo2012}.  The basic system of type theory has the important property of \emph{strong normalization}, which yields a decision procedure for equality of terms, as well as an algorithm for determining whether a term has a specified type and thus ``whether a purported proof is really a proof".  Does the system still have this property (or an equally useful one) if one adds the Univalence Axiom?  What about if one adds other homotopically motivated constructions, like the \emph{higher inductive types} used to introduce the spheres $S^n$?  These questions remain open at the present time --- although methods are currently being developed to try to find answers.

Another basic issue is the difficulty of working with types, like the natural numbers, which are essentially sets (i.e., discrete homotopy types), with only trivial paths, and which nonetheless possess many non-reflexivity identity terms, albeit essentially trivial ones.  These ``meaningless" identity terms introduce needless complications into arguments and constructions, and so it would be convenient to have a systematic way of eliminating or collapsing them to judgemental equalities.  In some cases (like the definition of a simplicial type), the proliferation of such superfluous identity terms makes it very difficult, if not impossible, to formulate what should be a straightforward concept.

But by far the largest field of work to be done is in the on-going formalization of everyday mathematics in this new system.  Recent successes in formalizing some facts from basic homotopy theory have been encouraging, but, obviously, much work remains to be done.

%\subsection*{Some references?}
%
%Some other surveys and introductions?

}%%%%%%%%%%%%% end of scope of local macros

% Local Variables:
% TeX-master: "main"
% End:
