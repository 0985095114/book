\chapter*{Appendix}

%\documentclass[12pt,a4paper]{amsart}
%\documentclass[10pt,a4paper]{article}
\ifx\pdfpageheight\undefined\PassOptionsToPackage{dvips}{graphicx}\else%
\PassOptionsToPackage{pdftex}{graphicx}
\PassOptionsToPackage{pdftex}{color}
\fi

\newcommand{\mkbox}[1]{\ensuremath{#1}}

\newcommand{\Prod}[2]{\displaystyle\prod _{#1}~#2}
\newcommand{\Sum}[2]{\displaystyle\sum _{#1}~#2}

\newcommand{\app}{\mathsf{app}}

\newcommand{\gothic}{\mathfrak}
\newcommand{\gP}{{\gothic p}}
\newcommand{\gM}{{\gothic M}}
\newcommand{\gN}{{\gothic N}}
\newcommand{\rats}{\mathbb{Q}}
\newcommand{\ints}{\mathbb{Z}}

\usepackage{epsf}
\usepackage{epsfig}
% \usepackage{isolatin1}
\usepackage{a4wide}
\usepackage{verbatim}
\usepackage{proof}
\usepackage{latexsym}
\usepackage{amssymb}
% \usepackage{stmaryrd}

%\usepackage{mytheorems}
%\newtheorem{proposition}[theorem]{Proposition}

%\documentstyle{article}


\setlength{\oddsidemargin}{0in} % so, left margin is 1in
\setlength{\textwidth}{6.27in} % so, right margin is 1in
\setlength{\topmargin}{0in} % so, top margin is 1in
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textheight}{9.19in} % so, foot margin is 1.5in
\setlength{\footskip}{.8in}

% Definition of \placetitle
% Want to do an alternative which takes arguments
% for the names, authors etc.

\newcommand{\lbr}{\lbrack\!\lbrack}
\newcommand{\rbr}{\rbrack\!\rbrack}
\newcommand{\sem}[2] {\lbr #1 \rbr_{#2}}  % interpretation of the terms
\newcommand{\APP}[2] {{\sf app}(#1,#2)}  % interpretation of the terms
\newcommand{\nats}{\mathbb{N}}
\newcommand{\Con}{{\sf Con}}
\newcommand{\Type}{{\sf Type}}
\newcommand{\Elem}{{\sf Elem}}
\newcommand{\id}{1}
\newcommand{\pp}{{\sf p}}
\newcommand{\qq}{{\sf q}}
\newcommand{\Sp}{{\sf Sp}}

\newcommand{\conv}{~{\sf conv}~}
\newcommand{\SUP}{{\sf sup}}
\newcommand{\PAIR}{{\sf pair}}
\newcommand{\suc}{{\sf s}}
\newcommand{\UU}{{\sf U}}
\newcommand{\WW}{{\sf W}}
\newcommand{\NN}{{\sf N}}
\newcommand{\Ord}{{\sf Ord}}
\newcommand{\LIM}{{\sf lim}}
\newcommand{\nn}{{\sf n}}
\newcommand{\zero}{{\sf 0}}

\newcommand{\Fam}{{\sf Fam}}
\newcommand{\pacomment}[1]{}
\newcommand{\refl}[1]{{\sf refl_{#1}}}

In this appendix we give a presentation of a version of intensional
Dependent Type Theory. 

The role of this appendix is to give a concise, simple, but we believe
precise, informal presentation of a formal type theory, that can be
used as a standard of mathematical rigour for the informal work in
Martin-L\"{o}f's intensional dependent type theory.  If the work in
Homotopy Type Theory can, in principle, be represented in this formal
type theory when extra axioms and rules like the Univalence Axiom and
rules for Higher Dimensional Inductive Definitions have been added,
then the claim is that the mathematics has met this standard of
rigour.

\section*{The Raw Syntax}
 The terms and types of our type theory are written using the following syntax, which is an extension
of $\lambda$-calculus with {\em primitive} $c,c',\dots$ and {\em defined} $f,f',\dots$
constants
$$
t,u,A,B~~~::=~~~x~|~\lambda x.t~|~t(u)~|~c~|~f
$$

 We follow the usual convention about free and bound variables. In particular,
we write $B[a/x]$ or simply $B[a]$ if the variable $x$ is clear from the context, for the 
substitution of $a$ for $x$ in $B$, with possible renaming for avoiding clash of variables.
More generally if $J$ is a judgement, we may write $J[a/x]$ or simply $J[a]$ for the 
judgement obtained by substitution of $a$ for $x$ in $J$.

\medskip

 We may write $t(t_1,\dots,t_n)$ for $t(t_1)(t_2)\dots (t_n)$.  Also sometimes we use infix notation, writing $t_1\; u\; t2$ rather than $u(t_1)(t_2)$ when $u$ is a primitive or defined constant.

\medskip

 Each defined constant will have zero, one or more {\em defining equations}.  There will be two kinds of defined constant.  The first {\em explicit} kind of defined constant $f$ will have a single {\em explicit definition}
  \[ f(x_1,\dots,x_n):= t\]
where $t$ does not involve $f$.  An example of explicit definition will be used later.  We introduce the defined constant 
$o$, for composition of functions, with explicit definition
  \[ \circ (x,y)(z) := x(y(z))\]
and use infix notation $x\circ y$ for $\circ(x,y)$.



The other kind of defined constant will be used in connection with a form of type having some primitive constants that are used to introduce elements into types of that form.  With each such primitive constant $c$ there will be a defining equation of the form
$$
f(x_1,\dots,x_n,c(y_1,\dots,y_m)) ~:=~ t,
$$
where now $f$ may occur in $t$, but now only in such a way that, in the context where $f$ is introduced it will be a totally defined typed function.
The paradigm examples of such defined functions are the functions defined by primitive recursion on the natural numbers.  We may call this kind of definition of a function a {\em total recursive definition}.  In computer science and logic this kind of definition of a function on a recursive data type has been called a {\em definition by structural recursion}

Together with $\beta$-conversion
$$
(\lambda x.t)(u) ~:=~ t[u/x]
$$
and thinking of $:=$ as a rewriting rule (unfolding definitions),
this forms a rewriting system which has the confluence (or Church-Rosser) property: we can
define $t~\conv~u$ to mean that $t$ and $u$ can be reduced to the same term by using
$\beta$-reduction and recursion.

\section*{The Forms of judgement}

 In type theory, we mainly derive assertions or judgements of the form $A~\Type$ for ``$A$ is a correct type'' or $a:A$ for ``$a$ is a correct term of type $A$.  It will also be useful to have judgements of the form $B~\Fam(A)$
for ``$B$ is a correct family of types, $B(x)$ for $x:A$''.
The judgement $A=B~\Type$ is defined to mean $A~\Type,~B~\Type$ and $A\conv B$
while the judgement $t=u:A$ is defined to mean $t:A,~u:A$ and $t\conv u$.
In general
these assertions are done inside a {\em context} (or ``space of parameters''), which is of
the form
$$
\Gamma ~=~  x_1:A_1,~x_2:A_2,\dots,~x_n:A_n
$$
and we write, for example, $A~\Type~(\Gamma)$ and $a:A~(\Gamma)$. 

 We write simply $A~\Type$ and $a:A$ if the context is empty, or if the context
can be omitted without ambiguity.

 If $x_1:A_1,~x_2:A_2,\dots,~x_n:A_n$ is a context, this means that we have
derived $A_1~\Type$ and then $A_2~\Type~(x_1:A_1)$, and $A_3~\Type~(x_1:A_1,x_2:A_2)$
$\dots$

\medskip
%\pagebreak

\section*{The Rules of a Basic Type Theory}
Here we give rules for some standard basic forms of type; the forms 

  $$\Pi(A,B),\NN,\NN_0,\NN_1,\NN_2,\Sigma(A,B),A_1+A_2,\Ord,\WW(A,B)
    \mbox{ and }Id(A,a,a').$$
%
Among the primitive constants, we have $\Pi$ and we write $(\Pi x:A)B$ instead
of $\Pi(A,\lambda x.B)$. We write $A\rightarrow B$ instead of $(\Pi x:A)B$ if
$x$ is not free in $B$.

\medskip

\subsection{The General and $\Pi$ Rules}
 The basic general rules of type theory are 
\begin{itemize}
\item if $B~\Type~(x:A)$ then $\lambda x.B~\Fam(A)$
\item if $B~\Fam(A)$ then 
\begin{itemize}
\item if $a:A$ then $B(a)~\Type$,
\item $\Pi(A,B)~\Type$,
\item if $b:B(x)~(x:A)$ then $\lambda x.b:\Pi(A,B)$, and
\item if $c:\Pi(A,B)$ and $a:A$ then $c(a):B(a)$
\end{itemize}
\item if $a:A$ and $A= B$ then $a:B$
\end{itemize}

\medskip

 When writing rules we follow the convention that we don't write explicitely the whole context.  For instance the more explicit rule for abstraction should be: if $b:B(x)~(\Gamma,x:A)$ then $\lambda x.b:\Pi(A,B)~(\Gamma)$.

\medskip

We now present the basic forms of primitive type.  

\subsection*{The Type of Natural Numbers}
We start with
the type of natural numbers, which  is obtained by adding primitive constants
$\NN,~\zero,~\suc$ with the following rules.
\begin{itemize}
\item $\NN~\Type$,
\item $\zero:\NN$,
\item $\suc:\NN\rightarrow \NN$.
\end{itemize}

 Furthermore, we can define functions by primitive recursion.  If we have
$C~\Fam(\NN)$ we can introduce $f:\Pi(\NN,C)$ whenever we have
$$
d:C(\zero)~~~~~~~e:(\Pi x:\NN)(C(x)\rightarrow C(\suc (x)))
$$
with the defining equations
$$
f(\zero) ~:=~ d~~~~~~~~~~~~f(\suc (x)) ~:=~ e(x,f(x))
$$
 
As usual $C,d,e$ may have been obtained in an implicit context $\Gamma$ in which variables $x_1,\ldots,x_n$ are declared.  Then there will be the extra implicit parameters $x_1,\ldots,x_n$, so that the fully explicit primitive recursion schema is
$$
f(x_1,\dots,x_n)(\zero) ~:=~ d[x_1,\dots,x_n]~~~~~~~~f(x_1,\dots,x_n)(\suc (x)) ~:=~ e[x_1,\dots,x_n,x,f(x_1,\dots,x_n)(x)]
$$

\medskip
\subsection*{The Finite Types $\NN_0,\NN_1,\NN_2$}

$0,1$ and, for $k=0,1,2$, $\NN_k$ are introduced as primitive constants with the rules

\begin{itemize}
\item $\NN_k~\Type$ for $k=0,1,2$,
\item $0:\NN_1$, $0:\NN_2$ and $1:\NN_2$.
\end{itemize}
 For $k=0,1,2$, if we have $C~\Fam(\NN_k)$ we can introduce $f:\Pi(\NN_k,C)$.  
\begin{itemize}
\item When $k=0$ $f$ has no defining equation.  
\item When $k=1$, if $c_0:C(0)$ then $f$ has the defining equation
  \[ f(0):= c_0.\]
\item When $k=2$, if $c_0:C(0)$ and $c_1:C(1)$ then $f$ has the defining equations
  \[ f(0):= c_0\mbox{ and } f(1):=c_1.\]
\end{itemize}
\pacomment{%%%%%%%%%%%%%%%%%
\begin{itemize}
 \item The {\em empty type} $\NN_0$ is introduced as a primitive constant with the rule
\begin{itemize}
\item $\NN_0~\Type$
\end{itemize}

 If we have $C~\Fam(\NN_0)$ we can introduce $f:\Pi(\NN_0,C)$.  Note that in this case there is no defining equation.
In the special case where $C$ is $\lambda x.C_0$ where $C_0$ does not contain $x$ free, this represents the usual law of absurd elimination $\NN_0\rightarrow C_0$.

\medskip

\item The {\em one element type} $\NN_1$ is introduced, together with $0$, as primitive constants with the rules
\begin{itemize}
\item $\NN_1~\Type$,
\item $0:\NN_1$.
\end{itemize}
If we have $C~\Fam(\NN_1)$ and $c_0:C(0)$ we can introduce the defined function 
$f:(\Pi(\NN_1,C)$ with defining equation
  \[ f(0)~:=~c_0.\]
\item The {\em two element type} $\NN_2$ is introduced, together with $0,1$, as primitive constants with the rules
\begin{itemize}
\item $\NN_2~\Type$,
\item $0:\NN_2$ and $1:\NN_2$
\end{itemize}
If we have $C~\Fam(\NN_2)$, $c_0:C(\nn^2_0)$ and $c_1:C(\nn^2_1)$ we can introduce the defined function 
$f:\Pi(\NN_2,C)$ with defining equations
  \[ f(0)~:=~c_0\mbox{ and }f(1)~:=~ c_1.\]
Note that $\NN_2$ is the type of boolean values, here $0$ and $1$.
\end{itemize}
}%%%end pacomment%%%%%%%%%%%%%%%%

\subsection*{$\Sigma$-Types}
For $\Sigma$-types we introduce primitive constants $\Sigma$ and $\PAIR$ with the rules
\begin{itemize}
\item if $B~\Fam(A)$ then $\Sigma(A,B)~\Type$, and
\item if $a:A$ and $b:B(a)$ then $\PAIR(a,b):\Sigma(A,B)$.
\end{itemize}
We write $(\Sigma x:A)B$ instead
of $\Sigma(A,\lambda x.B)$ and we write $A\times B$ instead of $(\Sigma x:A)B$ if
$x$ is not free in $B$.  If we have $C~\Fam(\Sigma(A,B))$ and
$
d:(\Pi x:A)(\Pi y:B(x))C(\PAIR(x,y))
$
we can introduce $f:\Pi(\Sigma(A,B),C)$ with the defining equation
$$
f(\PAIR(x,y))~:=~d(x,y).
$$

\medskip

\subsection*{Binary Sum Types $A_1+A_2$}
We introduce primitive constants $+,in_1,in_2$ with the rules
\begin{itemize}
\item if $A_1,A_2~\Type$ then $+(A_1,A_2)~\Type$, and
\item if $a:A_i$ then $in_i(a):A_i$, for $i=1,2$.
\end{itemize}
We write $A_1+A_2$ instead of $+(A_1,A_2)$.
If $C~\Fam(A_1+A_2)$ and $d_i:\Pi(A_i,C\circ in_i)$ for $i=1,2$, where 
$(C\circ in_i)(x)~:=~C(in_i(x))$, then we can introduce a defined constant $f:\Pi(A_1+A_2,C)$ with the defining equations
  \[ f(in_i(x))~:= ~d_i(x)\mbox{ for } i=1,2.\]

\subsection*{Types of ordinals}
We introduce primitive constants $\Ord,~\LIM$ with the rules
\begin{itemize}
\item $\Ord~\Type$
\item $\zero:\Ord$
\item $\suc:\Ord\rightarrow\Ord$
\item $\LIM:(\NN\rightarrow\Ord)\rightarrow\Ord$
\end{itemize}
If $C~\Fam(\Ord)$ and $d:C(\zero)$ and $e:(\Pi x:\Ord)(C(x)\rightarrow C(\suc(x)))$ and
$$g:(\Pi u:\NN\rightarrow\Ord)((\Pi n:\NN)C(u(n)))\rightarrow C(\LIM(u))$$
then we can introduce a defined constant $f:\Pi(\Ord,C)$ with the defining equations
$$
f(0) ~:=~ d~~~~~f(\suc(n)) ~:=~ e(n,f(n))~~~~~f(\LIM(u)) ~:=~ g(u,f\circ u)
$$
where $(f\circ u)(n) = f(u(n))$.

\subsection*{$\WW$-Types}
For $\WW$-types we introduce primitive constants $\WW$ and $\SUP$ with the rules
\begin{itemize}
\item if $B~\Fam(A)$ then $\WW(A,B)\Type$, and
\item if $a:A$ and $u:B(a)\rightarrow \WW(A,B)$ then $\SUP(a,u):\WW(A,B)$.
\end{itemize}
 
 Here also we can define functions by total recursion. If we have
$C~\Fam(\WW(A,B))$ we can introduce $f:(\Pi z:\WW(A,B))C(z)$ whenever we have
$$
d:(\Pi x:A)(\Pi u:B(x)\rightarrow \WW(A,B))((\Pi y:B)C(u(y)))\rightarrow C(\SUP(x,u))
$$
with the defining equation
$$
f(\SUP(x,u)) ~:=~ d(x,u,f\circ u)
$$
where $(f\circ u)(y) ~:=~ f(u(y))$.

\subsection*{Identity Types $Id_A(a,a')$}
We introduce primitive constants $Id$ and $\refl{}$ with the rules
\begin{itemize}
\item if $A~\Type$ and $a:A$ then $Id(A,a)~\Fam(A)$, and
\item if $a:A$ then $\refl{a}:Id(A,a)(a)$.
\end{itemize}
If $C~\Type~(y:A,z:Id(A,a,y))$ and $d:C[a,\refl{a}]$ then we can introduce a defined constant 
  $$f:(\Pi y:A)(\Pi z:Id(A,a))C$$ 
with defining equation
  \[ f(a,\refl{a}):= d.\]
When we make explicit a variable declaration $x:A$ 
and let $a$ be $x$ 
so that we have 
  $$C~\Type~(x,y:A, z:Id(A,x,y))\mbox{ and  }d:(\Pi x:A)C[x,x,\refl{x}]$$ 
then we have the defined constant
  $$f':(\Pi x,y:A)(\Pi z:Id(A,x,y))C$$ 
with defining equation
  \[ f'(x,x,\refl{x}):= d(x).\]
This defined constant $f'$, with its defining equation, corresponds to the rules for identity types originally formulated by Per Martin-L\"{o}f.   The defined constant $f$, with its defining equation, corresponds to the rules given later by Christine Paulin-Mohring.  It is not entirely trivial to recapture $f$ from $f'$.


\section*{Type Universes}

 A type theory can be extended by introducing a type universe $\UU$ with rules that ``reflect'' the forms of type previously considered, here the forms of type of the basic type theory.  The general rules for $\UU$ are

\begin{itemize}
\item $\UU~\Type$, and
\item $A~\Type$ if $A:\UU$.
\end{itemize}

The rules reflecting the forms of type of the basic type theory are

\begin{itemize}
\item $\NN,\NN_0\NN_1,\NN_2:\UU$,
\item if $A_1,A_2:\UU$ then $A_1+A_2:\UU$,
\item if $A:\UU$ and $B:A\rightarrow\UU$ then     $\Pi(A,B),\Sigma(A,B),\WW(A,B):\UU$, and 
\item if $A:\UU$ and $a,a':A$ then $Id(A,a,a'):\UU$.
\end{itemize}

Having added the type universe $\UU$ we may introduce another type universe
$\UU^+$ that has all the previous rules that $\UU$ has, but in addition reflects the above two general rules of $\UU$; i.e. it has the rules

\medskip

\begin{itemize}
\item $\UU:\UU^+$, and
\item $A:\UU^+$ if $A:\UU$.
\end{itemize}

\medskip

Iterating we get an infinite hierarchy of universes $\UU_0,\UU_1,\ldots$, where
$\UU_0=\UU$ and $\UU_{n+1}=\UU_n^+$ for $n=0,1,\ldots$.
\pacomment{%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
\item $\UU_n~\Type$
\item $A~\Type$ if $A:\UU_n$
\item $A:\UU_{n+1}$ if $A:\UU_n$
\item $\UU_n:\UU_{n+1}$
\end{itemize}
 }%%%%%%%%%%%%%END pacomment%%%%%%%%%%%%%%%%%%%%%

\medskip
\subsection*{Some Syntactical Properties of the Type Theory}
 This system has the following syntactical properties.

\begin{thm}\label{red}
If $A~\Type$ and $A$ reduces to $A'$ then $A'~\Type$.
If $t:A$ and $t$ reduces to $t'$ then $t':A$.
\end{thm}

\begin{thm}\label{SN}
 If $A~\Type$ then $A$ is strongly normalizable.
If $t:A$ then $A$ and $t$ are strongly normalizable. 
\end{thm}

 We say that a term is {\em in normal form} if it cannot be reduced.
A closed normal type has to be a primitive type, i.e. of the form $c(\vec{v})$ for some
primitive constant $c$ (where $\vec{v}$ may be empty, for instance $\NN$). 
More generally we have the following explicit description of terms in normal form.

\begin{lemma}\label{normal}
The terms in normal form can be described by the following syntax
$$
v~::=~ k~|~\lambda x.v~|~c(\vec{v})~|~f(\vec{v})
$$
$$
k~::=~x~|~k(v)~|~f(\vec{v})(k)
$$
where $f(\vec{v})$ represents a partial application of the defined function $f$.
In particular, a type in normal form should be of the form $k$ or $c(\vec{v})$.
\end{lemma}

\begin{proposition}
If $A$ is in normal form then the 
judgement $A~\Type$ is decidable. If $A~\Type$ and $t$ is in normal form then the judgement
$t:A$ is decidable.
\end{proposition}


 A corollary is the {\em consistency} property: there is no proof of $\NN_0$ in the empty
context. Indeed if we have $t:\NN_0$ then by Theorems \ref{red} and \ref{SN} the term $t$ will reduce
to a term in normal form $t'$ which satsifies $t':\NN_0$, but this is not possible by a 
purely combinatorial argument using Lemma \ref{normal}. Similarly, we have the following
{\em canonicity} property: if $t:N$ in the empty context, then $t$ has to reduce to a
normal form $\suc^k(0)$ for some numeral $k$. Finally, it means that, if we restrict to term
in normal form, the typing relation is {\em decidable}, and identifying type-checking with
{\em proof-checking}, we can indeed ``recognize a proof of an assertion when we see one''.

\subsection*{General Remarks}

%This presentation is strongly inspired by two  Martin-L\"of 1972 and 1973.

 The system of rules with introduction (primitive constants) and elimination and computation rules
(defined constant) is inspired by Gentzen natural deduction. The possibility of strengthening
the elimination rule for existential quantification was indicated by Howard 1969. The strengthening
the axioms for disjunction appears in Martin-L\"of 1972, and for absurdity elimination and Identity type
in Martin-L\"of 1973. The $W$-types were introduced in Martin-L\"of 1979. They generalize a notion
of trees introduced by Tait 1968.%(himself inspired from unpublished work of Spector).

 The generalized form of primitive recursion for natural numbers and ordinals appear in Hilbert 1925.
This motivated G\"odel's system $T$, 1958, which was analyzed by Tait 1966, who used, following
G\"odel 1958, the terminology
``definitional equality'' for conversion: two terms are {\em definitionally equal} if they reduce
to a common term by means of a sequence of applications of the reduction rules. This terminology was
also used by de Bruijn 1973 in his presentation of Automath.

 Streicher 1991, Theorem 4.13, explains how to give the semantics in contextual category of terms in normal
form using a simple syntax similar to the one we have presented.

%\end{document}  


