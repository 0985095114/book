\chapter{Logic}
\label{cha:logic}

Type theory, formal or informal, is a collection of rules for manipulating types and their elements.
But when writing mathematics informally in human language, we generally use familiar words, particularly connectives such as ``and'' and ``or'', and quantifiers such as ``for all'' and ``there exists''.
In contrast to set theory, type theory offers us more than one choice for how to regard these English phrases as operations on types.
This potential ambiguity needs to be resolved, by setting out local or global conventions, by introducing new annotations to informal mathematics, or both.
This requires some getting used to, but is offset by the fact that because type theory permits this finer analysis of logic, we can represent mathematics more faithfully, with fewer ``abuses of language'' than in set-theoretic foundations.
In this chapter we will explain the issues involved, and justify the choices we have made in this book.


\section{The failure of classical logic}
\label{sec:patnonclass}

Until now, we have been following the straightforward ``propositions as types'' philosophy described in \S\ref{sec:pat}, according to which English phrases such as ``there exists an $x:A$ such that $P(x)$'' are interpreted by corresponding types such as $\sm{x:A} P(x)$, with the proof of a statement being regarded as judging some specific term to inhabit that type.
However, we have also seen some ways in which the ``logic'' resulting from this reading seems unfamiliar to a classical mathematician.
For instance, in \autoref{thm:ttac} we saw that the statement
\begin{quote}
  ``If for all $x:X$ there exists an $a:A(x)$ such that $P(x,a)$, then there exists a function $g:\prd{x:A} A(x)$ such that for all $x:X$ we have $P(x,g(x))$,''
\end{quote}
which looks like the classical \emph{axiom of choice}, is always true under this reading.
On the other hand, we can now show that corresponding statements looking like the classical \emph{law of double negation} and \emph{law of excluded middle} are incompatible with the univalence axiom.

\begin{thm}\label{thm:not-dneg}
  It is not the case that for all $A:\UU$ we have $\neg(\neg A) \to A$.
\end{thm}
\begin{proof}
  Recall that $\neg A \jdeq (A\to\emptyt)$.
  We also read ``it is not the case that \dots'' as the operator $\neg$.
  Thus, in order to prove this statement, it suffices to assume given some $f:\prd{A:\UU} (\neg\neg A \to A)$ and construct an element of \emptyt.

  The idea of the following proof is to observe that $f$, like any function, is automatically ``continuous'' with respect to paths in its domain.
  By univalence, this implies that $f$ is \emph{natural} with respect to equivalences of types.
  From this, and a fixed-point-free autoequivalence, we will be able to extract a contradiction.

  Recall that $\bool\defeq \unit+\unit$, and let $e:\eqv\bool\bool$ be the equivalence defined by $e(\inl(\ttt))\defeq\inr(\ttt)$ and $e(\inr(\ttt))\defeq\inl(\ttt)$, as in \autoref{thm:type-is-not-a-set}.
  Let $p:\bool=\bool$ be the path corresponding to $e$ by univalence, i.e.\ $p\defeq \ua(e)$.
  Then we have $f(\bool) : \neg\neg\bool \to\bool$ and
  \[\apd f p : \transfib{A\mapsto (\neg\neg A \to A)}{p}{f(\bool)} = f(\bool).\]
  Hence, for any $u:\neg\neg\bool$, we have
  \[\happly(\apd f p,u) : \transfib{A\mapsto (\neg\neg A \to A)}{p}{f(\bool)}(x) = f(\bool)(u).\]

  Now by~\eqref{eq:transport-arrow}, transporting $f(\bool):\neg\neg\bool\to\bool$ along $p$ in the type family ${A\mapsto (\neg\neg A \to A)}$ is equal to the function which transports its argument along $\opp p$ in the type family $A\mapsto \neg\neg A$, applies $f(\bool)$, then transports the result along $p$ in the type family $A\mapsto A$:
  \[ \transfib{A\mapsto (\neg\neg A \to A)}{p}{f(\bool)}(u) =
  \transfib{A\mapsto A}{p}{f(\bool) (\transfib{A\mapsto \neg\neg A}{\opp{p}}{u})}
  \]
  However, any two points $u,v:\neg\neg\bool$ are equal by function extensionality, since for any $x:\neg\bool$ we have $u(x):\emptyt$ and thus we can derive any conclusion, in particular $u(x)=v(x)$.
  Thus, we have $\transfib{A\mapsto \neg\neg A}{\opp{p}}{u} = u$, and so from $\happly(\apd f p,u)$ we obtain an equality
  \[ \transfib{A\mapsto A}{p}{f(\bool)(u)} = f(\bool)(u).\]
  Finally, as discussed in \S\ref{sec:compute-universe}, transporting in the type family $A\mapsto A$ along the path $p\jdeq \ua(e)$ is equivalent to applying the equivalence $e$; thus we have
  \begin{equation}
    e(f(\bool)(u)) = f(\bool)(u).\label{eq:fpaut}
  \end{equation}

  However, we can also prove that
  \begin{equation}
    \prd{x:\bool} \neg(e(x)=x).\label{eq:fpfaut}
  \end{equation}
  This follows from a case analysis on $x$: both cases are immediate from the definition of $e$ and the injectivity of $\inl$ and $\inr$ which we proved in \S\ref{sec:compute-coprod}.
  Thus, applying~\eqref{eq:fpfaut} to $f(\bool)(u)$ and~\eqref{eq:fpaut}, we obtain an element of $\emptyt$.
\end{proof}

\begin{cor}\label{thm:not-lem}
  It is not the case that for all $A:\UU$ we have $A+(\neg A)$.
\end{cor}
\begin{proof}
  Suppose we had $g:\prd{A:\UU} (A+(\neg A))$.
  We will show that then $\prd{A:\UU} (\neg\neg A \to A)$, so that we can apply \autoref{thm:not-dneg}.
  Thus, suppose $A:\UU$ and $u:\neg\neg A$; we want to construct an element of $A$.

  Now $g(A):A+(\neg A)$, so by case analysis, we may assume either $g(A)\jdeq \inl(a)$ for some $a:A$, or $g(A)\jdeq \inr(w)$ for some $w:\neg A$.
  In the first case, we have $a:A$, while in the second case we have $u(w):\emptyt$ and so we can obtain anything we wish (such as $A$).
  Thus, in both cases we have an element of $A$, as desired.
\end{proof}

In conclusion, although the propositions-as-types logic has many good properties (such as simplicity, constructivity, and computability), it is an uncomfortable place in which to try to do classical mathematics, especially from our homotopical point of view.


\section{Mere propositions}
\label{sec:hprops}

The good and bad things about propositions-as-types logic have a common cause: when types are viewed as propositions, they can contain more information than mere truth or falsity, and all ``logical'' constructions on them must respect this additional information.
This suggests that we could obtain a more classical logic by restricting attention to types that do \emph{not} contain any more information than truth or falsity.

Such a type will be ``true'' if it is inhabited and ``false'' if it is not inhabited.
What we want to avoid are types for which giving an element of them gives more information than simply knowing that the type is inhabited.
For instance, if we are given an element of \bool, then we receive more information than the mere fact that \bool contains some element.
Indeed, we receive exactly \emph{one bit} more information: we know \emph{which} element of \bool we were given.
By contrast, if we are given an element of \unit, then we receive no more information than the mere fact that \unit contains an element, since any two elements of \unit are equal to each other.
This suggests the following definition.

\begin{defn}
  A type $P$ is a \textbf{mere proposition} if for all $x,y:P$ we have $x=y$.
\end{defn}

Note that since we are still doing mathematics \emph{in} type theory, this is a definition \emph{in} type theory, which means it is a type --- or, rather, a type family.
Specifically, for any $P:\type$, the type $\isprop(P)$ is defined to be
\[ \isprop(P) \defeq \prd{x,y:P} (x=y). \]
Thus, to assert that ``$P$ is a mere proposition'' means to exhibit an inhabitant of $\isprop(P)$, which is a dependent function connecting any two elements of $P$ by a path.
The continuity/naturality of this function implies that not only are any two elements of $P$ equal, but $P$ contains no higher homotopy either.

\begin{lem}
  If $P$ is a mere proposition and $x_0:P$, then $\eqv P \unit$.
\end{lem}
\begin{proof}
  Define $f:P\to\unit$ by $f(x)\defeq \ttt$, and $g:\unit\to P$ by $g(u)\defeq x_0$.
  Then for any $u:\unit$ we have $\eqv{(f(g(u))=u)}{\unit}$, hence $f(g(u))=u$, while for any $x:P$ we have $g(f(x))=x$ since $P$ is a mere proposition.
\end{proof}

In homotopy theory, a space that is homotopy equivalent to \unit is said to be \emph{contractible}.
Thus, any mere proposition which is inhabited is contractible.
On the other hand, the uninhabited type \emptyt is also (vacuously) a mere proposition.
In classical mathematics, at least, these are the only two possibilities.

Mere propositions are also called \emph{subterminal objects} (if thinking categorically), \emph{subsingletons} (if thinking set-theoretically), or \emph{h-propositions}.
In Chapter~\ref{cha:hlevels} we will learn to also call them \emph{$(-1)$-truncated types}.
The adjective ``mere'' emphasizes that although any type may be regarded as a proposition (which we prove by giving an inhabitant of it), a type that is a mere proposition cannot usefully be regarded as any \emph{more} than a proposition: there is no additional information contained in a witness of its truth.

Note that a type $A$ is a set if and only if for all $x,y:A$, the identity type $\id[A]xy$ is a mere proposition.
On the other hand, by copying (and simplifying) the proof of \autoref{thm:isset-is1type}, we see that every mere proposition is a set.
We have seen one other example so far: condition~\ref{item:be3} in \S\ref{sec:basics-equivalences} asserts that for any function $f$, the type $\isequiv (f)$ should be a mere proposition.


We can now give the proper formulation of the \emph{law of excluded middle} in homotopy type theory:
\begin{equation}
  \label{eq:lem}
  \mathsf{LEM}\;\defeq\;
  \prd{A:\UU} \Big(\isprop(A) \to (A + \neg A)\Big).
\end{equation}
Similarly, the \emph{law of double negation} is
\begin{equation}
  \label{eq:ldn}
  \mathsf{DN}\;\defeq\;
  \prd{A:\UU} \Big(\isprop(A) \to (\neg\neg A \to A)\Big).
\end{equation}
These formulations avoid the paradoxes of \autoref{thm:not-dneg} and \autoref{thm:not-lem}, since \bool is not a mere proposition.
Although they are not consequences of the basic type theory described in Chapter~\ref{cha:typetheory}, they may be consistently assumed as axioms.
For instance, we will assume them in \S\ref{sec:wellorderings}.

However, it can be surprising how far we can get without using such axioms.
Quite often, a simple reformulation of a definition or theorem enables us to avoid invoking excluded middle or double negation.
This is even more pronounced in \emph{homotopy} type theory.
For instance, none of the homotopy theory we will develop in Chapter~\ref{cha:homotopy} requires LEM or DN, despite the fact that classical homotopy theory (formulated using topological spaces or simplicial sets) makes heavy use of them (as well as the axiom of choice).


\section{Subsets}
\label{sec:prop-subsets}

As another example of the usefulness of mere propositions, we discuss subsets (and more generally subtypes).
Suppose $P:A\to\type$ is a type family, with each type $P(x)$ regarded as a proposition.
Then $P$ itself is a \emph{predicate} on $A$, or a \emph{property} of elements of $A$.

In set theory, whenever we have a predicate on $P$ on a set $A$, we may form the subset $\setof{x\in A | P(x)}$.
In type theory, the obvious analogue is the $\Sigma$-type $\sm{x:A} P(x)$.
An inhabitant of $\sm{x:A} P(x)$ is, of course, a pair $(x,p)$ where $x:A$ and $p$ is a proof of $P(x)$.
However, for general $P$, an element $a:A$ might give rise to more than one distinct element of $\sm{x:A} P(x)$, if the proposition $P(a)$ has more than one distinct proof.
This is counter to the usual intuition of a \emph{subset}.
But if $P$ is a \emph{mere} proposition, then this cannot happen.

\begin{lem}
  Suppose $P:A\to\type$ is a type family such that $P(x)$ is a mere proposition for all $x:A$.
  If $u,v:\sm{x:A} P(x)$ are such that $\proj1(u) = \proj1(v)$, then $u=v$.
\end{lem}
\begin{proof}
  Suppose $p:\proj1(u) = \proj1(v)$.
  By \autoref{thm:path-sigma}, to show $u=v$ it suffices to show $\trans{p}{\proj2(u)} = \proj2(v)$.
  But $\trans{p}{\proj2(u)}$ and $\proj2(v)$ are both elements of $P(\proj1(v))$, which is a mere proposition; hence they are equal.
\end{proof}

For instance, recall that in \S\ref{sec:basics-equivalences} we defined
\[(\eqv A B) \;\defeq\; \sm{f:A\to B} \isequiv (f),\]
and that each type $\isequiv (f)$ is a mere proposition.
It follows that if two equivalences have equal underlying functions, then they are equal as equivalences.

Henceforth, if $P:A\to \type$ is a family of mere propositions, we will allow ourselves to write $\setof{x:A | P(x)}$ as an alternative notation for $\sm{x:A} P(x)$.


\section{The logic of mere propositions}
\label{sec:logic-hprop}

We mentioned in \S\ref{sec:types-vs-sets} that in contrast to type theory, which has only one basic notion (types), set-theoretic foundations have two basic notions: sets and propositions.
Thus, a classical mathematician is accustomed to manipulating these two kinds of objects separately.

It is possible to recover a similar dichotomy in type theory, with the role of the set-theoretic propositions being played by the types (and type families) that are \emph{mere} propositions.
In many cases, the logical connectives and quantifiers can be represented in this logic by simply restricting the corresponding type-former to the mere propositions.
Of course, this requires knowing that the type-former in question preserves mere propositions.

\begin{eg}
  If $A$ and $B$ are mere propositions, so is $A\times B$.
  This is easy to show using the characterization of paths in products, just like \autoref{thm:isset-prod} but simpler.
  Thus, the connective ``and'' preserves mere propositions.
\end{eg}

\begin{eg}\label{thm:isprop-forall}
  If $A$ is any type and $B:A\to \type$ is such that for all $x:A$, the type $B(x)$ is a mere proposition, then $\prd{x:A} B(x)$ is a mere proposition.
  The proof is just like \autoref{thm:isset-forall} but simpler: given $f,g:\prd{x:A} B(x)$, for any $x:A$ we have $f(x)=g(x)$ since $B(x)$ is a mere proposition.
  But then by function extensionality, we have $f=g$.

  In particular, if $B$ is a mere proposition, then so is $A\to B$ regardless of what $A$ is.
  In even more particular, since \emptyt is a mere proposition, so is $\neg A \jdeq (A\to\emptyt)$.
  Thus, the connectives ``implies'' and ``not'' preserve mere propositions, as does the quantifier ``for all''.
\end{eg}

On the other hand, some type formers do not preserve mere propositions.
Even if $A$ and $B$ are mere propositions, $A+B$ will not in general be.
For instance, \unit is a mere proposition, but $\bool\defeq\unit+\unit$ is not.
Logically speaking, $A+B$ is a ``purely constructive'' sort of ``or'': a witness of it contains the additional information of \emph{which} disjunct is true.
Sometimes this is very useful, but if we want a more classical sort of ``or'' that preserves mere propositions, we need a way to ``truncate'' this type into a mere proposition by forgetting this additional information.

The same issue arises with the $\Sigma$-type $\sm{x:A} P(x)$.
This is a purely constructive interpretation of ``there exists an $x:A$ such that $P(x)$'' which remembers the witness $x$, and hence is not generally a mere proposition even if each type $P(x)$ is.
(Recall that we observed in \S\ref{sec:prop-subsets} that $\sm{x:A} P(x)$ can also be regarded as ``the subset of those $x:A$ such that $P(x)$''.
The tension between these two interpretations is exactly the point.)


\section{Propositional truncation}
\label{sec:prop-trunc}

The \emph{propositional truncation}, also called the \emph{$(-1)$-truncation}, \emph{bracket type}, or \emph{squash type}, is an additional type former which ``truncates'' or ``squashes'' a type down to a mere proposition, forgetting all information contained in inhabitants of that type other than their existence.

More precisely, for any type $A$, there is a type $\brck{A}$.
It has two constructors:
\begin{itemize}
\item For any $a:A$ we have $\bproj a : \brck A$.
  Thus, if $A$ is inhabited, so is $\brck A$.
\item For any $x,y:\brck A$, we have $x=y$.
  In other words, $\brck A$ is a mere proposition; usually we leave the witness of this fact nameless.
\end{itemize}
The induction principle of $\brck A$ says that:
\begin{itemize}
\item If $B$ is a mere proposition and we have $f:A\to B$, then there is an induced $g:\brck A \to B$ such that $g(\bproj a) \jdeq f(a)$ for all $a:A$.
\end{itemize}
Thus, $\brck A$, as a mere proposition, contains no more information than the inhabitedness of $A$, since any mere proposition which follows from the inhabitedness of $A$ already follows from $\brck A$.

With the propositional truncation, we can extend the ``logic of mere propositions'' to cover disjunction and the existential quantifier.
Specifically, $\brck{A+B}$ is a mere propositional version of ``$A$ or $B$'', which does not ``remember'' the information of which disjunct is true.

The induction principle of truncation implies that we can still do a case analysis on $\brck{A+B}$ \emph{when attempting to prove a mere proposition}.
That is, suppose we have an assumption $u:\brck{A+B}$ and we are trying to prove a mere proposition $Q$.
In other words, we are trying to define an element of $\brck{A+B} \to Q$.
Since $Q$ is a mere propositon, by the induction principle for propositional truncation, it suffices to construct a function $A+B\to Q$.
But now we can use case analysis on $A+B$.

Similarly, for a type family $P:A\to\type$, we can consider $\brck{\sm{x:A} P(x)}$, which is a mere propositional version of ``there exists an $x:A$ such that $P(x)$''.
As for disjunction, by combining the induction principles of truncation and $\Sigma$-types, if we have an assumption of type $\brck{\sm{x:A} P(x)}$, we may introduce new assumptions $x:A$ and $y:P(x)$ \emph{when attempting to prove a mere proposition}.
In other words, if we know that there exists some $x:A$ such that $P(x)$, but we don't have a particular such $x$ in hand, then we are free to make use of such an $x$ as long as we aren't trying to construct anything which might depend on the particular value of $x$.
Requiring the codomain to be a mere proposition expresses this independence of the result on the witness, since all possible inhabitants of such a type must be equal.

We can now properly formulate the \emph{axiom of choice} in homotopy type theory.
Assume a type $X$ and type families $A:X\to\type$ and $P:\prd{x:X} A(x)\to\type$, and moreover that
\begin{itemize}
\item $X$ is a set,
\item $A(x)$ is a set for all $x:X$, and
\item $P(x,a)$ is a mere proposition for all $x:X$ and $a:A(x)$.
\end{itemize}
The axiom of choice asserts that under these assumptions,
\begin{multline}\label{eq:ac}
  \left(\prd{x:X} \Brck{\sm{a:A(x)} P(x,a)}\right)
  \to\\
  \Brck{\sm{g:\prd{x:X} A(x)} \prd{x:X} P(x,g(x))}
\end{multline}
Note that the propositional truncation appears twice.
The truncation in the domain means we assume that for every $x$ there exists some $a:A(x)$ such that $P(x,a)$, but that these values are not chosen or specified in any known way.
The truncation in the codomain means we conclude that there exists some function $g$, but this function is not determined or specified in any known way.

As with LEM and DN,~\eqref{eq:ac} is not a consequence of our basic type theory, but it may consistently be assumed as an axiom.
Note the restriction to types that are sets; because of the continuity/functoriality of all functions, it is unreasonable to assert such a statement without some such restriction.

\begin{rmk}
  A word of caution about a common pitfall: although dependent function types preserve mere propositions (\autoref{thm:isprop-forall}), they do not commute with truncation: $\brck{\prd{x:A} P(x)}$ is not generally equivalent to $\prd{x:A} \brck{P(x)}$.
  Indeed, while the version of the ``axiom of choice'' which is provable in type theory is really just a statement about how $\Sigma$'s and $\Pi$'s commute, the proper axiom of choice~\eqref{eq:ac} is arguably a statement about how $\Pi$'s commute with truncation.
\end{rmk}


\section{When are propositions truncated?}
\label{sec:when-trunc}

At first glance, it may seem that the truncated versions of $+$ and $\Sigma$ are closer to the informal mathematical meaning of ``or'' and ``there exists''.
Certainly, they are closer to the \emph{precise} meaning of ``or'' and ``there exists'' in the first-order logic which underlies formal set theory, since the latter makes no attempt to remember any witnesses to the truth of propositions.
However, frequently the practice of \emph{informal} mathematics is more accurately described by the untruncated forms.

For example, consider a statement like ``every prime number is either $2$ or odd.''
The working mathematician feels no compunction about using this fact not only to prove \emph{theorems} about prime numbers, but also to perform \emph{constructions} on prime numbers, perhaps doing one thing in the case of $2$ and another in the case of an odd prime.
Since the end result of the construction is not merely the truth of some statement, but a piece of data which may depend on the parity of the prime number, from a type-theoretic perspective such a construction is naturally phrased using the induction principle for the coproduct type ``$(p=2)+(p\text{ is odd})$'', not its propositional truncation.

Admittedly, this is not an ideal example, since ``$p=2$'' and ``$p$ is odd'' are mutually exclusive, so that $(p=2)+(p\text{ is odd})$ is in fact already a mere proposition and hence equivalent to its truncation (see Exercises~\ref{ex:disjoint-or} and~\ref{ex:prop-eqvtrunc}).
More compelling examples come from the existential quantifier.
It is not uncommon to prove a theorem of the form ``there exists an $x$ such that \dots'' and then refer later on to ``the $x$ constructed in Theorem Y'' (note the definite article).
Moreover, when deriving further properties of this $x$, one may use phrases such as ``by the construction of $x$ in the proof of Theorem Y''.

A very common example is ``$A$ is isomorphic to $B$'', which strictly speaking means only that there exists \emph{some} isomorphism between $A$ and $B$.
But almost invariably, when proving such a statement one exhibits a specific isomorphism, or proves that some previously known map is an isomorphism, and it often matters later on what particular isomorphism was given.

Honest, set-theoretically trained mathematicians generally feel a twinge of guilt at such ``abuses of language''.
We may attempt to apologize for them, expunge them from final drafts, or weasel out of them with vague words like ``canonical''.
The problem is exacerbated by the fact that in formalized set theory, there is technically no way to ``construct'' objects at all --- we can only prove that an object with certain properties exists.
Untruncated logic in type theory thus validates common practices of informal mathematics which set theory disparages.
(This is similar to how the univalence axiom validates the common, but formally unjustified, practice of identifying isomorphic objects.)

On the other hand, sometimes truncated logic is essential.
We have seen this in the statements of LEM and AC; some other examples will appear later on in the book.
Thus, we are faced with the problem: when writing informal type theory, what should we mean by the words ``or'' and ``there exists'' (along with common synonyms such as ``there is'' and ``we have'')?

A universal consensus may not be possible.
Perhaps depending on the sort of mathematics being done, one convention or the other may be more useful --- or, perhaps, the choice of convention may be irrelevant.
In this case, a remark at the beginning of a mathematical paper may suffice to inform the reader of the linguistic conventions in use therein.
However, even after one overall convention is chosen, the other sort of logic will usually arise at least occasionally, so we need a way to refer to it.
More generally, one may consider replacing the propositional truncation with another operation on types that behaves similarly, such as the double negation $A\mapsto \neg\neg A$, or the $n$-truncations to be considered in Chapter~\ref{cha:hlevels}.
We propose the use of \emph{adverbs} to denote the application of such ``modalities''.

For instance, if untruncated logic is the overall convention, we may use the adverb \textbf{merely} to denote propositional truncation.
Thus the phrase
\begin{center}
  ``there merely exists an $x:A$ such that $P(x)$''
\end{center}
indicates the type $\brck{\sm{x:A} P(x)}$.
On the other hand, if truncated logic is the current default convention, we may use an adverb such as \textbf{purely} or \textbf{constructively} to indicate its absence, so that
\begin{center}
``there purely exists an $x:A$ such that $P(x)$''
\end{center}
would denote the type $\sm{x:A} P(x)$.
We may also use ``purely'' just to emphasize the absence of truncation, even when that is the default convention.

In this book we will continue using untruncated logic as the default convention, for a number of reasons.
\begin{enumerate}[label=(\arabic*)]
\item We want to encourage the newcomer to experiment with it, rather than sticking to truncated logic simply because it is more familiar.
\item Using truncated logic as the default in type theory suffers from the same sort of ``abuse of language'' problems as set-theoretic foundations, which untruncated logic avoids.
  For instance, our definition of ``$\eqv A B$'' as the type of equivalences between $A$ and $B$, rather than its propositional truncation, means that to prove a theorem of the form ``$\eqv A B$'' is literally to construct a particular such equivalence.
  This specific equivalence can then be referred to later on.
\item We want to emphasize that the notion of ``mere proposition'' is not a fundamental part of type theory.
  As we will see in Chapter~\ref{cha:hlevels}, mere propositions are just the second rung on an infinite ladder, and there are also many other modalities not lying on this ladder at all.
\item Many statements that classically are mere propositions are no longer so in homotopy type theory.
  Of course, foremost among these is equality.
\item On the other hand, one of the most interesting observations of homotopy type theory is that a surprising number of types are \emph{automatically} mere propositions, or can be slightly modified to become so, without the need for any truncation.
  (See \autoref{ex:isprop-isprop} and Chapters~\ref{cha:equivalences}, \ref{cha:hlevels}, \ref{cha:category-theory}, and~\ref{cha:set-math}.)
  Thus, although these types contain no data beyond a truth value, we can nevertheless use them to construct untruncated objects, since there is no need to use the induction principle of propositional truncation.
  This useful fact is more clumsy to express if propositional truncation is applied to all statements by default.
\item Finally, truncations are not very useful for most of the mathematics we will be doing in this book, so it is simpler to notate them explicitly when they occur.
\end{enumerate}


\section*{Notes}

\autoref{thm:not-dneg} and \autoref{thm:not-lem} can be traced back to a classical theorem of Hedberg, which we will prove in Chapter~\ref{cha:hlevels}.
The proof we have given of \autoref{thm:not-dneg} is due to Thierry Coquand.

Mere propositions were first defined in type theory by Voevodsky.
His original definition was slightly more complicated than ours, but fits into the more general framework of Chapter~\ref{cha:hlevels}.

The propositional truncation was introduced, in extensional type theory, by~\cite{ab:bracket-types}.
The intensional version was constructed by Voevodsky using an impredicative quantification, and later by Lumsdaine using higher inductive types (see Chapter~\ref{cha:hits}).


\section*{Exercises}
\label{sec:exercises}

\begin{ex}
  Show that if $A$ is a mere proposition, then so is $A+(\neg A)$.
  Thus, there is no need to insert a propositional truncation in~\eqref{eq:lem}.
\end{ex}

\begin{ex}\label{ex:disjoint-or}
  More generally, show that if $A$ and $B$ are mere propositions and $\neg(A\times B)$, then $A+B$ is also a mere proposition.
\end{ex}

\begin{ex}
  Show that if $A$ and $B$ are mere propositions such that $A\to B$ and $B\to A$, then $\eqv A B$.
\end{ex}

\begin{ex}\label{ex:isprop-isprop}
  Show that for any type $A$, the types $\isprop(A)$ and $\isset(A)$ are mere propositions.
\end{ex}

\begin{ex}\label{ex:prop-eqvtrunc}
  Show that if $A$ is already a mere proposition, then $\eqv A{\brck{A}}$.
\end{ex}

\begin{ex}\label{ex:brck-qinv}
  Assuming that some type $\isequiv(f)$ satisfies conditions~\ref{item:be1}--\ref{item:be3} of \S\ref{sec:basics-equivalences}, show that the type $\brck{\mathsf{qinv}(f)}$ satisfies the same conditions and is equivalent to $\isequiv(f)$.
\end{ex}

\begin{ex}
  Show that it is not the case that for all $A:\type$ we have $\brck{A} \to A$.
  (However, there can be particular types for which $\brck{A}\to A$.
  \autoref{ex:brck-qinv} implies that $\mathsf{qinv}(f)$ is such.)
\end{ex}

\begin{ex}
  Show that the rules for the propositional truncation given in \S\ref{sec:prop-trunc} are sufficient to imply a dependent version of the induction principle: for any type family $B:\brck A \to \type$ such that each $B(x)$ is a mere proposition, if for every $a:A$ we have $B(\bproj a)$, then for every $x:\brck A$ we have $B(x)$.
\end{ex}

% Local Variables:
% TeX-master: "main"
% End:
